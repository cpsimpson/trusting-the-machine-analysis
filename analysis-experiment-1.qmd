---
title: "Analysis"
author: "Caroline Simpson"
format: 
  html:
    theme: cerulean
    df-print: kable
    # df-print: paged
    code-fold: false
    toc: true
    toc-float:
      collapsed: true
      smooth-scroll: false
    toc-depth: 7

editor: visual
---

```{r include=FALSE}
#| label: setup

library(knitr)
library(kableExtra)


source("./scripts/data-loading.R", local = TRUE)
source("./scripts/data-cleaning.R", local = TRUE)
source("./scripts/analysis-data-properties.R", local = TRUE)
source("./scripts/analysis-descriptives.R", local = TRUE)
source("./scripts/analysis-reliability.R", local = TRUE)
source("./scripts/analysis-inferential.R", local = TRUE)
source("./scripts/analysis-correlation.R", local = TRUE)
source("./scripts/analysis-regression.R", local = TRUE)
source("./scripts/analysis-moderation-mediation.R", local = TRUE)
source("./scripts/plotting.R", local = TRUE)
source("./scripts/common.R", local = TRUE)

library(tidyverse)

directory_setup()
theme_set(my_theme)

s1_study <- "s1"

```

# Trusting the machine: Epistemic trust and anthropomorphism in generative artificial intelligence

**Research Question**: What effect does anthropomorphism have on level of trust in generative AI and the content it creates?

My **hypothesis** is that there will be an increase in epistemic trust with increasing levels of anthropomorphism.

## Data Analysis

### Load data

```{r}
s1_raw_data <- load_data(s1_study)
s1_raw_data <- factorize_data(s1_study, s1_raw_data)
```

Number of participants in raw data = `r nrow(s1_raw_data)`.

```{r}

s1_raw_data <- explode_chatbots_used(s1_raw_data)

s1_raw_data <- explode_languages(s1_raw_data)

```

### Exclude non-consent

```{r}
s1_raw_data <- exclude_non_consenting_participants(s1_raw_data)
```

### Manual Processing

Reviewed and coded Survey purpose check (what they think this study is about, not the attention check)

-   Manually coded the response values with the following key:

    -   0 = no answer provided

    -   1 = identified the survey was about AI content, perception of AI, human versus AI distinction

    -   2 = nonsensical text

    -   3 = values that describe a purpose (not about AI)

    -   4 = random word

    -   5 = unsure

    -   6 = "the study was interesting" or "good" and variations of this

    -   7 = None

```{r}
summarize_columns(s1_raw_data, SurveyTopicCheck_coded)
```

Reviewed and coded Unrealistic parts of survey.

-   Unrealistic field is a separate field with the values of:

    -   1 = No

    -   2 = Yes

-   Unrealistic_coded -\> Manually coded the response values from Unrealistic_2_TEXT field with the following key:

    -   0 = no answer provided

    -   1 = believe descriptions written by AI or content written by AI when told human or content written by human when told AI

    -   2 = don't believe that traits make sense to apply to AI

    -   3 = it all seemed realistic

    -   4 = description of AI was not believable

    -   5 = random text

    -   6 = unsure why they were asked questions about AI (in High condition)

```{r}

s1_raw_data |> summarize_columns(Unrealistic)

s1_raw_data |> summarize_columns(Unrealistic, Unrealistic_coded) 
```

### Clean Data

No ability to check for duplicates because we recruited through CloudResearch and don't have ids. Assume that the platform prevents duplicate participant responses.

```{r}
recruited_participants <- s1_raw_data |> count_recruited_participants(s1_study)
```

Number of participants recruited = `r recruited_participants`.

```{r}
s1_cleaned_data <- s1_raw_data |> clean_data(s1_study)

```

Number of participants after basic filtering = `r nrow(s1_cleaned_data)`.

### Fill missing values

#### Assess skewness and distribution

```{r}

# Compute skewness for each numeric variable
s1_cleaned_data |> check_skewness(s1_study)

# Shapiro-Wilk normality test 
s1_cleaned_data |>
  dplyr::select(-Progress, -ConsentForm, -`Duration (in seconds)`, -Status, -Finished, -TopicCheck, -GodspeedMETI_28, -GodspeedMETI_29, -AIChatbotsUsed_NA, -Reread, -LanguagesFluent_NA) |>
  check_normality(s1_study)

```

#### Fill missing values with median values

Populate missing values with the median within Condition.

```{r}

missing_values_within_conditions(s1_cleaned_data)

# Perform imputation only on selected variables
s1_imputed_data <- impute_data(s1_cleaned_data)

missing_values_within_conditions(s1_imputed_data)

```

### Reverse Coding

Reverse code items for each scale where appropriate

```{r}
s1_recoded_data <- s1_imputed_data |> recode_data(s1_study)
```

#### Standardize Scale Item Values

```{r}

s1_cleaned_data <- s1_recoded_data |> standardize_data()

```

#### Regroup data

Regroup the AIChatbotsFrequency, Education, and Age columns into smaller number of categories of data for analysis. Some of the more granular categories don't have a large enough sample for meaningful comparisons.

```{r}

s1_cleaned_data <- s1_cleaned_data |> regroup_data()

```

### Calculate Scale Scores

#### Define Score Components

```{r}
s1_cleaned_data <- s1_cleaned_data |> compute_scores(s1_study)

s1_cleaned_data <- s1_cleaned_data |> bin_scores(s1_study)
```

```{r}
s1_cleaned_data <- s1_cleaned_data |> cast_variables(s1_study)
```

### Scale Inter-item Reliability Analysis

#### Anthropomorphism (Godspeed Subscale)

```{r}

basic_descriptives(s1_cleaned_data$anthropomorphism_score)

s1_cleaned_data |> cronbachs_alpha(get_anthropomorphism_score_godspeed_cols())

```

#### Likeability (Godspeed Subscale)

```{r}

basic_descriptives(s1_cleaned_data$likeability_score)

s1_cleaned_data |> cronbachs_alpha(get_likeability_score_godspeed_cols())

```

#### Competence (Godspeed Subscale)

```{r}

basic_descriptives(s1_cleaned_data$competence_score)

s1_cleaned_data |> cronbachs_alpha(get_competence_score_godspeed_cols())

```

#### Expertise (METI Subscale)

```{r}

basic_descriptives(s1_cleaned_data$expertise_score)

s1_cleaned_data |> cronbachs_alpha(get_expertise_score_METI_cols())

```

#### Integrity (METI Subscale)

```{r}

basic_descriptives(s1_cleaned_data$integrity_score)

s1_cleaned_data |> cronbachs_alpha(get_integrity_score_METI_cols())


```

#### Benevolence (METI Subscale)

```{r}
basic_descriptives(s1_cleaned_data$benevolence_score)

s1_cleaned_data |> cronbachs_alpha(get_benevolence_score_METI_cols())

```

#### METI (Author Trust)

```{r}

basic_descriptives(s1_cleaned_data$author_trust_METI_score)

s1_cleaned_data |> cronbachs_alpha(get_author_trust_score_METI_cols())

```

#### Trust Behaviour (Author Trust)

```{r}
basic_descriptives(s1_cleaned_data$author_trust_behaviour_score)

s1_cleaned_data |> cronbachs_alpha(get_author_trust_score_behaviour_cols(s1_study))

```

#### Combine Author Trust

```{r}

basic_descriptives(s1_cleaned_data$author_trust_combined_score)

s1_cleaned_data |> cronbachs_alpha(get_author_trust_score_combined_cols(s1_study))


```

#### Appelman (Content Trust)

```{r}
basic_descriptives(s1_cleaned_data$content_trust_appelman_score)

s1_cleaned_data |> cronbachs_alpha(get_content_trust_score_appelman_cols())

```

#### Trust Behaviour (Content Trust)

```{r}
basic_descriptives(s1_cleaned_data$content_trust_behaviour_score)

s1_cleaned_data |> cronbachs_alpha(get_content_trust_score_behaviour_cols())

```

#### Combined Content Trust

```{r}

basic_descriptives(s1_cleaned_data$content_trust_combined_score)

s1_cleaned_data |> cronbachs_alpha(get_content_trust_score_combined_cols())

```

#### Expertise / Intentions

```{r}
basic_descriptives(s1_cleaned_data$intention_to_use_score)
s1_cleaned_data |> cronbachs_alpha(get_intention_cols())


basic_descriptives(s1_cleaned_data$fear_of_ai_score)
s1_cleaned_data |> cronbachs_alpha(get_fear_cols())


basic_descriptives(s1_cleaned_data$writing_expertise)
s1_cleaned_data |> cronbachs_alpha(get_writing_experience_cols())


basic_descriptives(s1_cleaned_data$science_expertise)
s1_cleaned_data |> cronbachs_alpha(get_science_experience_cols())


basic_descriptives(s1_cleaned_data$writing_quality_score)
s1_cleaned_data |> cronbachs_alpha(get_writing_quality_cols())

```

### Sample Characteristics

```         
N=`r length(unique(s1_cleaned_data$ResponseId))`
```

#### Study duration (in minutes)

```{r}
basic_descriptives(s1_cleaned_data$`Duration (in seconds)` / 60)
```

#### Participants reporting Technical Issues (Not removed in data cleaning)

```{r}
s1_cleaned_data |> 
  summarize_columns(TechnicalIssues) 

s1_cleaned_data |> 
  summarize_columns(TechnicalIssues, Condition) 
```

```{r}
s1_cleaned_data |> 
  summarize_columns(Unrealistic) 

s1_cleaned_data |> 
  summarize_columns(Unrealistic, Condition) 

s1_cleaned_data |> 
  summarize_columns(Unrealistic_coded) 

s1_cleaned_data |> 
  summarize_columns(Unrealistic_coded, Condition) 
```

#### Participants per condition.

```{r}
s1_cleaned_data |> 
  summarize_columns(Condition)

```

#### Age

```         
Age range: `r round(min(s1_cleaned_data$Age_1, na.rm = TRUE), 2)` to `r round(max(s1_cleaned_data$Age_1, na.rm = TRUE), 2)`
Mean age: `r round(mean(s1_cleaned_data$Age_1, na.rm = TRUE), 2)`
Standard deviation: `r round(sd(s1_cleaned_data$Age_1, na.rm = TRUE), 2)`
```

```{r}
s1_cleaned_data |> 
  summarize_columns(age_range)

s1_cleaned_data |> 
  summarize_columns(age_range, Condition) 
```

#### Gender

```{r}

s1_cleaned_data |> 
  summarize_columns(Gender) 

s1_cleaned_data |> 
  summarize_columns(Gender, Condition) 

```

#### Sex

```{r}

s1_cleaned_data |> 
  summarize_columns(Sex)

s1_cleaned_data |> 
  summarize_columns(Sex, Condition)
```

#### Education Level

```{r}

s1_cleaned_data |> 
  summarize_columns(Education) 

s1_cleaned_data |> 
  summarize_columns(Education, Condition) 

s1_cleaned_data |> 
  summarize_columns(Education_regrouped) 

s1_cleaned_data |> 
  summarize_columns(Education_regrouped, Condition) 

```

#### AI Chatbot Usage

```{r}

s1_cleaned_data |> 
  summarize_columns(AIChatbotsFrequency) 

s1_cleaned_data |> 
  summarize_columns(AIChatbotsFrequency, Condition) 

s1_cleaned_data |> 
  summarize_columns(AIChatbotsFrequency_regrouped) 

s1_cleaned_data |> 
  summarize_columns(AIChatbotsFrequency_regrouped, Condition) 

s1_cleaned_data |> summarize_exploded_columns("AIChatbotsUsed", AIChatbotsUsed)
  
s1_cleaned_data |> summarize_exploded_columns("AIChatbotsUsed", AIChatbotsUsed, Condition)

```

#### Science Content Familiarity

```{r}

s1_cleaned_data |> 
  summarize_columns(ScienceContent) 

s1_cleaned_data |> 
  summarize_columns(ScienceContent, Condition) 

s1_cleaned_data |> 
  summarize_columns(ScienceContent_regrouped) 

s1_cleaned_data |> 
  summarize_columns(ScienceContent_regrouped, Condition) 

```

#### English as a First Language

```{r}

s1_cleaned_data |> 
  summarize_columns(English) 

s1_cleaned_data |> 
  summarize_columns(English, Condition) 
```

#### Other Languages

```{r}

s1_cleaned_data |> summarize_exploded_columns("LanguagesFluent", LanguagesFluent)

s1_cleaned_data |> summarize_exploded_columns("LanguagesFluent", LanguagesFluent, Condition)

```

### Manipulation Check

#### Anthropomorphism

##### Plot

```{r}

violin_plot(s1_cleaned_data, 
            s1_study,
            "Condition",
            "anthropomorphism_score",
            include_legend = FALSE)
```

##### Descriptive Statistics

```{r}
s1_cleaned_data |> descriptives_by_group(Condition, anthropomorphism_score) 
```

##### Inferential Statistics

###### ANOVA

```{r}
aov_model <- s1_cleaned_data |> run_between_subjects_anova(anthropomorphism_score ~ Condition, "anthropomorphism_score")

```

###### T-tests

```{r}
s1_cleaned_data |> run_simple_effects_t_tests(anthropomorphism_score ~ Condition)
```

#### Likeability

We were not explicitly intending to manipulate likeability

##### Plot

```{r}
violin_plot(s1_cleaned_data, 
            s1_study,
            "Condition",
            "likeability_score",
            include_legend = FALSE)
```

##### Descriptive Statistics

```{r}
s1_cleaned_data |> descriptives_by_group(Condition, likeability_score) 
```

##### Inferential Statistics

###### ANOVA

```{r}
aov_model <- s1_cleaned_data |> run_between_subjects_anova(likeability_score ~ Condition, "likeability_score")

```

###### T-tests

```{r}
s1_cleaned_data |> run_simple_effects_t_tests(likeability_score ~ Condition)
```

#### Competence

We were not explicitly intending to manipulate competence \##### Plot

```{r}
violin_plot(s1_cleaned_data, 
            s1_study,
            "Condition",
            "competence_score",
            include_legend = FALSE)
```

##### Descriptive Statistics

```{r}
s1_cleaned_data |> descriptives_by_group(Condition, competence_score) 
```

##### Inferential Statistics

###### ANOVA

```{r}
aov_model <- s1_cleaned_data |> run_between_subjects_anova(competence_score ~ Condition, "competence_score")

```

###### T-tests

```{r}
s1_cleaned_data |> run_simple_effects_t_tests(competence_score ~ Condition)
```

### Main Analysis

#### Content Trust

##### Plot

```{r}

plot <- violin_plot(s1_cleaned_data, 
            s1_study,
            "Condition",
            "content_trust_combined_score",
            include_legend = FALSE)

plot
```

##### Descriptive Statistics

```{r}

s1_cleaned_data |> descriptives_by_group(Condition, content_trust_combined_score)

```

##### Inferential Statistics

###### ANOVA

```{r}
aov_model <- s1_cleaned_data |> run_between_subjects_anova(content_trust_combined_score ~ Condition, "competence_score")

```

###### T-tests

```{r}
s1_cleaned_data |> run_simple_effects_t_tests(content_trust_combined_score ~ Condition)
```

##### Post-hoc Analysis

###### Sample Characteristics

```{r}

result <- s1_cleaned_data |> test_correlation(Age_1, content_trust_combined_score)
result

formulas <- c(content_trust_combined_score ~ Gender, 
              content_trust_combined_score ~ Sex, 
              content_trust_combined_score ~ Education #,
              # content_trust_combined_score ~ Education_regrouped
              )


for (i_formula in formulas){
  result <- s1_cleaned_data |> run_inferential(i_formula, share_fraction = 1 / 3)

if (!is.null(result) && result$test == "ANOVA"){
  result$apa_output
} else if (!is.null(result) && result$test == "t-test"){
  result$model
}
}



```

###### Sample Attitudes / Experience

```{r}
# Check for correlations between trust and variables
result <- s1_cleaned_data |> test_correlation(changed_opinion_of_ai_score, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(fear_of_ai_score, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(intention_to_use_score, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(writing_expertise, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(science_expertise, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(writing_quality_score, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(changed_opinion_of_ai_score, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(AIChatbotsFrequency, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(AIChatbotsFrequency_regrouped, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(ScienceContent, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(ScienceContent_regrouped, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(TechnicalIssues, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(Unrealistic, content_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(number_ai_chatbots_used, content_trust_combined_score)

```

```{r}
# Check for differences in means of trust across groups in various variables
formulas <- c(
              # content_trust_combined_score ~ AIChatbotsFrequency,
              content_trust_combined_score ~ AIChatbotsFrequency_regrouped,
              # content_trust_combined_score ~ ScienceContent,
              content_trust_combined_score ~ ScienceContent_regrouped,
              content_trust_combined_score ~ TechnicalIssues,
              content_trust_combined_score ~ Unrealistic,
              content_trust_combined_score ~ Unrealistic_coded, 
              content_trust_combined_score ~ AIChatbotsUsed_ChatGPT,
              content_trust_combined_score ~ AIChatbotsUsed_Gemini,
              content_trust_combined_score ~ AIChatbotsUsed_Grok,
              content_trust_combined_score ~ AIChatbotsUsed_Claude,
              content_trust_combined_score ~ AIChatbotsUsed_Other,
              content_trust_combined_score ~ AIChatbotsUsed_None,
              content_trust_combined_score ~ AIChatbotsUsed_Copilot, 
              content_trust_combined_score ~ number_ai_chatbots_used_f,
              content_trust_combined_score ~ intention_to_use_binned,
              content_trust_combined_score ~ fear_of_ai_binned,
              content_trust_combined_score ~ changed_opinion_of_ai_binned,
              content_trust_combined_score ~ writing_expertise_binned,
              content_trust_combined_score ~ science_expertise_binned,
              content_trust_combined_score ~ likeability_binned,
              content_trust_combined_score ~ competence_binned,
              content_trust_combined_score ~ anthropomorphism_binned
              
              )


for (i_formula in formulas){
  s1_cleaned_data |> descriptives_from_formula(i_formula)
  
  result <- s1_cleaned_data |> run_inferential(i_formula, share_fraction = 1 / 3)

  if (!is.null(result) && result$test == "ANOVA"){
    result$apa_output
    if (!is.null(result$pwt_result) && !all(is.na(result$pwt_result))){
      print("Summary")
      summary(result$pwt_result)
      print("Inf print")
      print(result$pwt_result, width=Inf)
    }
    
  } else if (!is.null(result) && result$test == "t-test"){
    result$model
  }
}

```

###### Hierarchical Regression Analysis

```{r}

result <- run_post_hoc_regression_analysis(
  data = s1_cleaned_data,
  dv = "content_trust_combined_score",
  study = s1_study
)

print(result)


```

###### Anthropomorphism

```{r}

s1_cleaned_data |> linear_model(content_trust_combined_score ~ anthropomorphism_score)
```

```{r}

s1_cleaned_data |> test_correlation("anthropomorphism_score", "content_trust_combined_score")

plot <- correlation_plot(s1_cleaned_data, 
            s1_study,
            "anthropomorphism_score",
            "content_trust_combined_score")

plot
```

#### Author Trust

##### Plot

```{r}
plot <- violin_plot(s1_cleaned_data, 
            s1_study,
            "Condition",
            "author_trust_combined_score",
            include_legend = FALSE)

plot
```

##### Descriptive Statistics

```{r}

s1_cleaned_data |> descriptives_by_group(Condition, author_trust_combined_score)
```

##### Inferential Statistics

###### Main Effect ANOVA

```{r}


result <- s1_cleaned_data |> run_inferential(author_trust_combined_score ~ Condition)
result$pwt_result

```

##### Post-hoc Analysis

###### Sample Characteristics

```{r}

result <- s1_cleaned_data |> test_correlation(Age_1, author_trust_combined_score)
result

formulas <- c(author_trust_combined_score ~ Gender, 
              author_trust_combined_score ~ Sex, 
              author_trust_combined_score ~ Education #,
              # author_trust_combined_score ~ Education_regrouped
              )


for (i_formula in formulas){
  
  s1_cleaned_data |> descriptives_from_formula(i_formula)
  
  result <- s1_cleaned_data |> run_inferential(i_formula, share_fraction = 1 / 3)

if (!is.null(result) && result$test == "ANOVA"){
  result$apa_output
} else if (!is.null(result) && result$test == "t-test"){
  result$model
}
}


```

###### Sample Attitudes / Experience

```{r}
# Check for correlations between trust and variables
result <- s1_cleaned_data |> test_correlation(changed_opinion_of_ai_score, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(fear_of_ai_score, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(intention_to_use_score, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(writing_expertise, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(science_expertise, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(writing_quality_score, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(changed_opinion_of_ai_score, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(AIChatbotsFrequency, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(AIChatbotsFrequency_regrouped, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(ScienceContent, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(ScienceContent_regrouped, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(TechnicalIssues, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(Unrealistic, author_trust_combined_score)
result <- s1_cleaned_data |> test_correlation(number_ai_chatbots_used, author_trust_combined_score)

```

```{r}
# Check for differences in means of trust across groups in various variables
formulas <- c(
              # content_trust_combined_score ~ AIChatbotsFrequency,
              author_trust_combined_score ~ AIChatbotsFrequency_regrouped,
              # content_trust_combined_score ~ ScienceContent,
              author_trust_combined_score ~ ScienceContent_regrouped,
              author_trust_combined_score ~ TechnicalIssues,
              author_trust_combined_score ~ Unrealistic,
              author_trust_combined_score ~ Unrealistic_coded, 
              author_trust_combined_score ~ AIChatbotsUsed_ChatGPT,
              author_trust_combined_score ~ AIChatbotsUsed_Gemini,
              author_trust_combined_score ~ AIChatbotsUsed_Grok,
              author_trust_combined_score ~ AIChatbotsUsed_Claude,
              author_trust_combined_score ~ AIChatbotsUsed_Other,
              author_trust_combined_score ~ AIChatbotsUsed_None,
              author_trust_combined_score ~ AIChatbotsUsed_Copilot, 
              author_trust_combined_score ~ number_ai_chatbots_used_f,
              author_trust_combined_score ~ intention_to_use_binned,
              author_trust_combined_score ~ fear_of_ai_binned,
              author_trust_combined_score ~ changed_opinion_of_ai_binned,
              author_trust_combined_score ~ writing_expertise_binned,
              author_trust_combined_score ~ science_expertise_binned,
              author_trust_combined_score ~ likeability_binned,
              author_trust_combined_score ~ competence_binned,
              author_trust_combined_score ~ anthropomorphism_binned
              
              )


for (i_formula in formulas){
  
  s1_cleaned_data |> descriptives_from_formula(i_formula)
  
  result <- s1_cleaned_data |> run_inferential(i_formula, share_fraction = 1 / 3)

  if (!is.null(result) && result$test == "ANOVA"){
    result$apa_output
    if (!is.null(result$pwt_result) && !all(is.na(result$pwt_result))){
      print("trying summary")
      summary(result$pwt_result)
      print("trying Inf print")
      print(result$pwt_result, width=Inf)
      # result$pwt_result |> rmarkdown::paged_table() |> print()
    }
    
  } else if (!is.null(result) && result$test == "t-test"){
    result$model
  }
}

```

###### Regression Analysis

```{r}

result <- run_post_hoc_regression_analysis(
  data = s1_cleaned_data,
  dv = "author_trust_combined_score",
  study = s1_study
)

print(result)


```

###### Anthropomorphism

```{r}

s1_cleaned_data |> linear_model(author_trust_combined_score ~ anthropomorphism_score)

```

```{r}

s1_cleaned_data |> test_correlation("anthropomorphism_score", "author_trust_combined_score")

plot <- correlation_plot(s1_cleaned_data, 
            s1_study,
            "anthropomorphism_score",
            "author_trust_combined_score")

plot


```

#### General Post Hoc

```{r}
s1_cleaned_data |> descriptives_by_group(Condition, Age_1)
s1_cleaned_data |> descriptives_by_group(Condition, Gender_n)
s1_cleaned_data |> descriptives_by_group(Condition, Sex_n)
s1_cleaned_data |> descriptives_by_group(Condition, English_n)
s1_cleaned_data |> descriptives_by_group(Condition, Education_n)
s1_cleaned_data |> descriptives_by_group(Condition, changed_opinion_of_ai_score)
s1_cleaned_data |> descriptives_by_group(Condition, changed_opinion_of_ai_binned_n)
s1_cleaned_data |> descriptives_by_group(Condition, fear_of_ai_score)
s1_cleaned_data |> descriptives_by_group(Condition, fear_of_ai_binned_n)
s1_cleaned_data |> descriptives_by_group(Condition, intention_to_use_score)
s1_cleaned_data |> descriptives_by_group(Condition, intention_to_use_binned_n)
s1_cleaned_data |> descriptives_by_group(Condition, writing_expertise)
s1_cleaned_data |> descriptives_by_group(Condition, writing_expertise_binned_n)
s1_cleaned_data |> descriptives_by_group(Condition, science_expertise)
s1_cleaned_data |> descriptives_by_group(Condition, science_expertise_binned_n)
s1_cleaned_data |> descriptives_by_group(Condition, writing_quality_score)
s1_cleaned_data |> descriptives_by_group(Condition, writing_quality_binned_n)

s1_cleaned_data |> descriptives_by_group(Condition, AIChatbotsFrequency_n)
s1_cleaned_data |> descriptives_by_group(Condition, AIChatbotsFrequency_regrouped_n)
s1_cleaned_data |> descriptives_by_group(Condition, ScienceContent_n)
s1_cleaned_data |> descriptives_by_group(Condition, ScienceContent_regrouped_n)
s1_cleaned_data |> descriptives_by_group(Condition, TechnicalIssues_n)
s1_cleaned_data |> descriptives_by_group(Condition, Unrealistic_n)
s1_cleaned_data |> descriptives_by_group(Condition, number_ai_chatbots_used)

s1_cleaned_data |> descriptives_by_group(Condition, AIChatbotsUsed_ChatGPT_n)
s1_cleaned_data |> descriptives_by_group(Condition, AIChatbotsUsed_Gemini_n)
s1_cleaned_data |> descriptives_by_group(Condition, AIChatbotsUsed_Grok_n)
s1_cleaned_data |> descriptives_by_group(Condition, AIChatbotsUsed_Claude_n)
s1_cleaned_data |> descriptives_by_group(Condition, AIChatbotsUsed_Copilot_n)
s1_cleaned_data |> descriptives_by_group(Condition, AIChatbotsUsed_Other_n)
s1_cleaned_data |> descriptives_by_group(Condition, AIChatbotsUsed_None_n)

s1_cleaned_data |> descriptives_by_group(Condition, likeability_score)
s1_cleaned_data |> descriptives_by_group(Condition, competence_score)
s1_cleaned_data |> descriptives_by_group(Condition, anthropomorphism_score)

```

```{r}
# Check for differences in means of trust across groups in various variables
formulas <- c(
              Age_1 ~ Condition,
              Gender_n ~ Condition,
              Sex_n ~ Condition,
              English_n ~ Condition,
              Education_n ~ Condition,
              Unrealistic_n ~ Condition,
              TechnicalIssues_n ~ Condition,
              AIChatbotsFrequency_n ~ Condition,
              AIChatbotsFrequency_regrouped_n ~ Condition,
              ScienceContent_n ~ Condition,
              ScienceContent_regrouped_n ~ Condition,
              AIChatbotsUsed_ChatGPT_n ~ Condition,
              AIChatbotsUsed_Gemini_n ~ Condition,
              AIChatbotsUsed_Grok_n ~ Condition,
              AIChatbotsUsed_Claude_n ~ Condition,
              AIChatbotsUsed_Other_n ~ Condition,
              AIChatbotsUsed_None_n ~ Condition,
              AIChatbotsUsed_Copilot_n ~ Condition, 
              number_ai_chatbots_used ~ Condition,
              intention_to_use_score ~ Condition,
              fear_of_ai_score ~ Condition,
              changed_opinion_of_ai_score ~ Condition,
              writing_quality_score ~ Condition,
              writing_expertise ~ Condition,
              science_expertise ~ Condition,
              likeability_score ~ Condition,
              competence_score ~ Condition,
              anthropomorphism_score ~ Condition
              
              )


for (i_formula in formulas){

  s1_cleaned_data |> descriptives_from_formula(i_formula)
  
  result <- s1_cleaned_data |> run_inferential(i_formula, share_fraction = 1 / 3)

  if (!is.null(result) && result$test == "ANOVA"){
    result$apa_output
    if (!is.null(result$pwt_result) && !all(is.na(result$pwt_result))){
      summary(result$pwt_result)
      print(result$pwt_result, width=Inf)
      result$pwt_result |> rmarkdown::paged_table() |> print()
    }
    
  } else if (!is.null(result) && result$test == "t-test"){
    result$model
  }
}

```

#### Interaction Effects

```{r}
model <- aov(formula = content_trust_combined_score ~ writing_quality_binned * fear_of_ai_binned, data = s1_cleaned_data)
summary(model)

print(effectsize::omega_squared(model))

# Mediator model
med_model <- lm(writing_quality_score ~ fear_of_ai_score, data = s1_cleaned_data)

# Outcome model
out_model <- lm(content_trust_combined_score ~ writing_quality_score + fear_of_ai_score, data = s1_cleaned_data)

mediation_result <- mediation::mediate(med_model, out_model,
                            treat = "fear_of_ai_score",
                            mediator = "writing_quality_score",
                            boot = TRUE, sims = 5000)

summary(mediation_result)
plot(mediation_result)


model <- aov(formula = content_trust_combined_score ~ writing_quality_binned * AIChatbotsFrequency, data = s1_cleaned_data)
summary(model)
print(effectsize::omega_squared(model))


# Mediator model
med_model <- lm(writing_quality_score ~ AIChatbotsFrequency, data = s1_cleaned_data)

# Outcome model
out_model <- lm(content_trust_combined_score ~ writing_quality_score + AIChatbotsFrequency, data = s1_cleaned_data)

mediation_result <- mediation::mediate(med_model, out_model,
                            treat = "AIChatbotsFrequency",
                            mediator = "writing_quality_score",
                            boot = TRUE, sims = 5000)

summary(mediation_result)
plot(mediation_result)

```

```{r}
# Step 1: Create a summary data frame with means and confidence intervals
summary_data <- s1_cleaned_data %>%
  group_by(writing_quality_binned, AIChatbotsFrequency_regrouped) %>%
  summarise(
    mean_ct = mean(content_trust_combined_score, na.rm = TRUE),
    se_ct = sd(content_trust_combined_score, na.rm = TRUE) / sqrt(n()),
    .groups = 'drop'
  ) %>%
  mutate(
  lower = mean_ct - se_ct,
  upper = mean_ct + se_ct
)

# Step 2: Plot using ggplot2
plot <- ggplot(summary_data, aes(
  x = writing_quality_binned,
  y = mean_ct,
  group = AIChatbotsFrequency_regrouped,
  color = AIChatbotsFrequency_regrouped, 
  shape = AIChatbotsFrequency_regrouped
)) +
  geom_line(
    data = summary_data,
    aes(
      x = writing_quality_binned,
      y = mean_ct,
      group = AIChatbotsFrequency_regrouped
    ),
    position = position_dodge(width = 0.1),
    size = 1
  ) +
  geom_point(
    data = summary_data,
    aes(y = mean_ct),
    position = position_dodge(width = 0.1),
    size = 3
  ) +
  geom_errorbar(
    data = summary_data,
    aes(ymin = lower, ymax = upper),
    position = position_dodge(width = 0.1),
    width = 0.2
  ) +
  # geom_line(size = 1) +
  # geom_point(size = 3) +
  # geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1) +
  labs(
    x = "Perceived Writing Quality (Binned)",
    y = "Mean Content Trust",
    color = "Frequency of AI Use (Binned)",
    shape = "Frequency of AI Use (Binned)",
    title = "Interaction of Writing Quality and Fear of AI on Content Trust"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "top") + 
    scale_color_manual(values = pal_4) +
  my_theme

 ggsave(paste(sep = "/", "plots", s1_study, "interaction_ai_use_writing_quality.png"),
         plot = plot,
         create.dir = TRUE)
 
 plot
```

<!-- #### ANCOVA Tests -->

```{r}
# s1_cleaned_data %>% 
#   group_by(Condition) %>%  
#   rstatix::get_summary_stats(writing_quality_score, type="common")
# 
# s1_cleaned_data %>% 
#   group_by(Condition) %>%  
#   rstatix::get_summary_stats(fear_of_ai_score, type="common")
# 
# s1_cleaned_data %>% 
#   group_by(Condition) %>%  
#   rstatix::get_summary_stats(content_trust_combined_score, type="common")
# 
# 
# rstatix::anova_test(data = s1_cleaned_data, formula = content_trust_combined_score ~ writing_quality_binned + fear_of_ai_score, type = 3, detailed = TRUE) # type 3 SS should be used in ANCOVA
# 
# 
# adj_means <- rstatix::emmeans_test(data = s1_cleaned_data, formula = content_trust_combined_score ~ writing_quality_binned, covariate = c(fear_of_ai_score))
# rstatix::get_emmeans(adj_means)
# 
# rstatix::emmeans_test(data = s1_cleaned_data, formula = content_trust_combined_score ~ writing_quality_binned, covariate = c(fear_of_ai_score), p.adjust.method = "fdr")
```

#### Path Analysis

```{r}

s1_cleaned_data$Condition_Compressed <- ifelse(s1_cleaned_data$Condition == "High", 1, 0)

s1_cleaned_data$Condition_Medium <- ifelse(s1_cleaned_data$Condition == "Medium", 1, 0)
s1_cleaned_data$Condition_High <- ifelse(s1_cleaned_data$Condition == "High", 1, 0)

s1_cleaned_data$ScienceContent_ordinal <- as.numeric(factor(s1_cleaned_data$ScienceContent_regrouped,
                                              levels = c("rarely", "occasionally", "frequently")))

s1_cleaned_data$AIChatbotsFrequency_ordinal <- as.numeric(factor(s1_cleaned_data$AIChatbotsFrequency_regrouped,
                                              levels = c("rarely", "occasionally", "frequently")))

s1_cleaned_data$intention_to_use_score_n <- as.numeric(s1_cleaned_data$intention_to_use_score)

s1_gen_ai_con_only_data <- s1_cleaned_data |> filter(Condition != "High") 
s1_gen_ai_con_only_data$Condition <- factor(s1_gen_ai_con_only_data$Condition, levels = c("Low", "Medium"))

```

```{r}
# s1_model_full <- '
#   
#   anthropomorphism_score ~ Condition_Compressed
#   likeability_score ~ Condition_Compressed
#   competence_score ~ Condition_Compressed
#   
#   ai_attitudes =~ AIChatbotsFrequency_ordinal + intention_to_use_score_n + fear_of_ai_score
#   author_perceptions =~ anthropomorphism_score + likeability_score + competence_score + expertise_score + integrity_score + benevolence_score
#   
#   author_perceptions ~ ai_attitudes
#   
#   # content_experience =~ ScienceContent_ordinal + science_expertise
#   writing_quality =~ writing_quality_score + content_trust_appelman_score
#   
#   # author_trust ~ author_perceptions + ai_attitudes
#   # 
#   # content_trust ~ ScienceContent_ordinal + science_expertise + writing_quality
#   
#   # author_trust ~ content_trust
#   
#   author_trust_behaviour_score ~ author_perceptions + ai_attitudes
#   content_trust_behaviour_score ~ ScienceContent_ordinal + science_expertise + writing_quality + author_perceptions + ai_attitudes
#   
# 
# 
# 
#   # Correlations
#   competence_score ~~ anthropomorphism_score 
#   likeability_score ~~ anthropomorphism_score
#   competence_score ~~ likeability_score
#   
# 
# '

# s1_model_full_fit <- s1_cleaned_data |> test_med_mod_model(s1_model_full)
```

```{r}
# lavaan::summary(s1_model_full_fit, fit.measures = TRUE, standardized = TRUE, ci = TRUE)
```

```{r}
# lavaan::inspect(s1_model_full_fit, "r2")
```

```{r}
# export_sem_results_to_word(s1_model_full_fit, s1_study, "full_model")
```

```{r}
# plot <- plot_model(s1_model_full_fit, s1_study)
# plot
```

```{r}
s1_model_trimmed <- '
  
  anthropomorphism_score ~ a1*Condition_Compressed
  likeability_score ~ b1*Condition_Compressed
  competence_score ~ c1*Condition_Compressed
  
  writing_quality_score ~ content_trust_combined_score
  content_trust_combined_score ~ writing_quality_score
  author_trust_combined_score ~ likeability_score + competence_score + anthropomorphism_score
  content_trust_combined_score ~ e1*author_trust_combined_score 

    # Optional: bidirectional path (uncomment if theoretically justified)
  author_trust_combined_score ~ f1*content_trust_combined_score

  # Optional: or use covariance if you don’t want to assume direction
  # author_trust_combined_score ~~ content_trust_combined_score
  
  # Correlations
  ScienceContent_ordinal ~~ content_trust_combined_score
  
  competence_score ~~ anthropomorphism_score 
  likeability_score ~~ anthropomorphism_score
  competence_score ~~ likeability_score
  
  # writing_quality_score ~~ content_trust_combined_score
  
  # Indirect effects
  ind1 := b1 * e1           # Condition → Anthro → Author Trust  → Content Trust
  ind2 := a1 * e1           # Condition → Likeability → Author Trust → Content Trust
  ind3 := c1 * e1           # Condition → Competence → Author Trust → Content Trust

'

s1_model_trimmed_fit <- s1_cleaned_data |> test_med_mod_model(s1_model_trimmed)
```

```{r}
lavaan::summary(s1_model_trimmed_fit, fit.measures = TRUE, standardized = TRUE, ci = TRUE)
```

```{r}
lavaan::inspect(s1_model_trimmed_fit, "r2")
```

```{r}
export_sem_results_to_word(s1_model_trimmed_fit, s1_study, "trimmed_model")
```

```{r}
plot <- plot_model(s1_model_trimmed_fit, s1_study)
plot
```

```{r}

labels <- list(Condition_Compressed = "Anthropomorphism Manipulation", 
               competence_score = "Perceived Intelligence", 
               likeability_score = "Perceived Likeability", 
               anthropomorphism_score = "Perceived Anthropomorphism", 
               author_trust_combined_score = "Author Trust", 
               content_trust_combined_score = "Content Trust",
               ScienceContent_ordinal = "Frequency of Science Content Consumption",
               writing_quality_score = "Writing Quality")

plot_lavaan_model(s1_model_trimmed_fit, labels, "trimmed", s1_study)

```

```{r}
lavaan::modindices(s1_model_trimmed_fit, sort = TRUE)
```

```{r}
# # Center the variables to reduce multicollinearity
# s1_cleaned_data$wrtng_c <- scale(s1_cleaned_data$writing_quality_score, scale = FALSE)
# s1_cleaned_data$fear_c <- scale(s1_cleaned_data$fear_of_ai_score, scale = FALSE)
# 
# # s1_cleaned_data$ai_attitudes_c <- rowMeans(s1_cleaned_data$fear_of_ai_score, as.numeric(s1_cleaned_data$AIChatbotsFrequency), )
# 
# # Create interaction term
# s1_cleaned_data$interaction <- s1_cleaned_data$wrtng_c * s1_cleaned_data$fear_c
# 
# # Run regression
# model <- lm(content_trust_combined_score ~ wrtng_c + fear_c + interaction, data = s1_cleaned_data)
# # summary(model)
# 
# # summary(multcomp::glht(model, linfct = multcomp::mcp(group = "Tukey")))
# 
# # model <- lm(content_trust_combined_score ~ writing_quality_score * fear_of_ai_score * AIChatbotsFrequency_regrouped * writing_expertise * science_expertise, data = s1_cleaned_data)
# #summary(model)

```

```{r}
# library(dplyr)
# 
# 
# # Calculate high/low splits
# low_fear <- mean(s1_cleaned_data$fear_of_ai_score, na.rm = TRUE) - sd(s1_cleaned_data$fear_of_ai_score, na.rm = TRUE)
# high_fear <- mean(s1_cleaned_data$fear_of_ai_score, na.rm = TRUE) + sd(s1_cleaned_data$fear_of_ai_score, na.rm = TRUE)
# 
# low_writing <- mean(s1_cleaned_data$writing_expertise, na.rm = TRUE) - sd(s1_cleaned_data$writing_expertise, na.rm = TRUE)
# high_writing <- mean(s1_cleaned_data$writing_expertise, na.rm = TRUE) + sd(s1_cleaned_data$writing_expertise, na.rm = TRUE)
# 
# low_science <- mean(s1_cleaned_data$science_expertise, na.rm = TRUE) - sd(s1_cleaned_data$science_expertise, na.rm = TRUE)
# high_science <- mean(s1_cleaned_data$science_expertise, na.rm = TRUE) + sd(s1_cleaned_data$science_expertise, na.rm = TRUE)
# 
# # Make prediction grid
# plot_data <- expand.grid(
#   writing_quality_score = seq(min(s1_cleaned_data$writing_quality_score, na.rm = TRUE),
#                               max(s1_cleaned_data$writing_quality_score, na.rm = TRUE),
#                               length.out = 100),
#   fear_of_ai_score = c(low_fear, high_fear),
#   AIChatbotsFrequency_regrouped = levels(s1_cleaned_data$AIChatbotsFrequency_regrouped),
#   writing_expertise = c(low_writing, high_writing),
#   science_expertise = c(low_science, high_science)
# )
# 
# # Predict values from model
# plot_data$predicted <- predict(model, newdata = plot_data)
# 
# # Label fear
# plot_data$fear_group <- factor(
#   plot_data$fear_of_ai_score,
#   levels = c(low_fear, high_fear),
#   labels = c("Low Fear", "High Fear")
# )
# 
# # Label writing expertise
# plot_data$writing_expertise_group <- factor(
#   plot_data$writing_expertise,
#   levels = c(low_writing, high_writing),
#   labels = c("Low Writing Expertise", "High Writing Expertise")
# )
# 
# # Label science expertise
# plot_data$science_expertise_group <- factor(
#   plot_data$science_expertise,
#   levels = c(low_science, high_science),
#   labels = c("Low Science Expertise", "High Science Expertise")
# )
# 
# # Label AI use
# plot_data$AI_use_group <- factor(
#   plot_data$AIChatbotsFrequency_regrouped,
#   levels = c("frequently", "occasionally", "rarely"),
#   labels = c("Frequent AI Use", "Occasional AI Use", "Rare AI Use")
# )
# 
# # Final plot
# ggplot(plot_data, aes(x = writing_quality_score, y = predicted, color = fear_group)) +
#   geom_line(size = 1.2) +
#   facet_grid(science_expertise_group ~ writing_expertise_group + AI_use_group) +
#   labs(
#     x = "Writing Quality",
#     y = "Predicted Content Trust",
#     color = "Fear of AI",
#     title = "Interaction: Writing × Fear × AI Use × Expertise"
#   ) +
#   theme_minimal(base_size = 12) +
#   theme(
#     strip.text.x = element_text(size = 10),
#     strip.text.y = element_text(size = 10),
#     legend.position = "bottom"
#   ) +
#   my_theme
# 
# 
# ggsave("plots/s1/writing_facet_plot.png", width = 16, height = 10, dpi = 300)

```

```{r}
# # Step 1: fear → writing quality
# m1 <- lm(writing_quality_score ~ fear_of_ai_score, data = s1_cleaned_data)
# 
# # Step 2: fear + writing quality → content trust
# m2 <- lm(content_trust_combined_score ~ fear_of_ai_score + writing_quality_score, data = s1_cleaned_data)
# 
# med_model <- mediation::mediate(m1, m2, treat = "fear_of_ai_score", mediator = "writing_quality_score", boot = TRUE, sims = 5000)
# summary(med_model)

```

```{r}

# s1_cleaned_data$wrtng_c <- as.numeric(scale(s1_cleaned_data$writing_quality_score, scale = FALSE))
# s1_cleaned_data$fear_c <- as.numeric(scale(s1_cleaned_data$fear_of_ai_score, scale = FALSE))
# s1_cleaned_data$wrtng_fear_interaction <- s1_cleaned_data$wrtng_c * s1_cleaned_data$fear_c
# 
# model <- lm(content_trust_combined_score ~ wrtng_c + fear_c + wrtng_fear_interaction,
#             data = s1_cleaned_data)
# 
# 
# low_fear <- mean(s1_cleaned_data$fear_c, na.rm = TRUE) - sd(s1_cleaned_data$fear_c, na.rm = TRUE)
# high_fear <- mean(s1_cleaned_data$fear_c, na.rm = TRUE) + sd(s1_cleaned_data$fear_c, na.rm = TRUE)
# 
# plot_data <- expand.grid(
#   wrtng_c = seq(min(s1_cleaned_data$wrtng_c, na.rm = TRUE),
#                 max(s1_cleaned_data$wrtng_c, na.rm = TRUE), length.out = 100),
#   fear_c = c(low_fear, high_fear)
# )
# 
# plot_data$wrtng_fear_interaction <- plot_data$wrtng_c * plot_data$fear_c
# plot_data$predicted <- predict(model, newdata = plot_data)
# plot_data$fear_group <- factor(plot_data$fear_c, labels = c("Low Fear", "High Fear"))
# 
# 
# ggplot2::ggplot(plot_data, aes(x = wrtng_c, y = predicted, color = fear_group)) +
#   geom_line(size = 1.2) +
#   labs(
#     x = "Centered Writing Quality",
#     y = "Predicted Content Trust",
#     color = "AI Fear",
#     title = "Interaction between Writing Quality and AI Fear on Content Trust"
#   ) +
#   theme_minimal()



```

```{r}
# s1_cleaned_data$wrtng_c <- scale(s1_cleaned_data$writing_quality_score, scale = FALSE)
# s1_cleaned_data$aiuse_c <- scale(as.numeric(s1_cleaned_data$AIChatbotsFrequency_regrouped), scale = FALSE)
# 
# # Create interaction term
# s1_cleaned_data$wrtng_aiuse_interaction <- s1_cleaned_data$wrtng_c * s1_cleaned_data$aiuse_c
# 
# # Run regression
# model <- lm(content_trust_combined_score ~ wrtng_c + aiuse_c + wrtng_aiuse_interaction, data = s1_cleaned_data)
# summary(model)
```

```{r}

# s1_cleaned_data$wrtng_c <- as.numeric(s1_cleaned_data$writing_quality_score)
# s1_cleaned_data$aiuse_c <- as.numeric(as.numeric(s1_cleaned_data$AIChatbotsFrequency_regrouped))
# s1_cleaned_data$wrtng_aiuse_interaction <- s1_cleaned_data$wrtng_c * s1_cleaned_data$aiuse_c
# 
# model <- lm(content_trust_combined_score ~ wrtng_c + aiuse_c + wrtng_aiuse_interaction,
#             data = s1_cleaned_data)
# 
# 
# low_aiuse <- mean(s1_cleaned_data$aiuse_c, na.rm = TRUE) - sd(s1_cleaned_data$aiuse_c, na.rm = TRUE)
# high_aiuse <- mean(s1_cleaned_data$aiuse_c, na.rm = TRUE) + sd(s1_cleaned_data$aiuse_c, na.rm = TRUE)
# 
# plot_data <- expand.grid(
#   wrtng_c = seq(min(s1_cleaned_data$wrtng_c, na.rm = TRUE),
#                 max(s1_cleaned_data$wrtng_c, na.rm = TRUE), length.out = 100),
#   aiuse_c = c(low_aiuse, high_aiuse)
# )
# 
# plot_data$wrtng_aiuse_interaction <- plot_data$wrtng_c * plot_data$aiuse_c
# plot_data$predicted <- predict(model, newdata = plot_data)
# plot_data$aiuse_group <- factor(plot_data$aiuse_c, labels = c("Low AI Use", "High AI Use"))
# 
# 
# ggplot2::ggplot(plot_data, aes(x = wrtng_c, y = predicted, color = aiuse_group)) +
#   geom_line(size = 1.2) +
#   labs(
#     x = "Centered Writing Quality",
#     y = "Predicted Content Trust",
#     color = "AI Use Frequency",
#     title = "Interaction between Writing Quality and AI Use on Content Trust"
#   ) +
#   theme_minimal()
# 


```

```{r}
# # Step 1: fear → writing quality
# m1 <- lm(writing_quality_score ~ AIChatbotsFrequency_regrouped, data = s1_cleaned_data)
# 
# # Step 2: fear + writing quality → content trust
# m2 <- lm(content_trust_combined_score ~ AIChatbotsFrequency_regrouped + writing_quality_score, data = s1_cleaned_data)
# 
# med_model <- mediation::mediate(m1, m2, treat = "AIChatbotsFrequency_regrouped", mediator = "writing_quality_score", boot = TRUE, sims = 5000)
# summary(med_model)
```

```{r}

```

#### Correlations

```{r}

s1_cleaned_data |> test_correlation("author_trust_combined_score", "content_trust_combined_score")

plots <- correlation_plot(s1_cleaned_data, 
            s1_study,
            "author_trust_combined_score",
            "content_trust_combined_score")

# Display the plots
plots$lm
plots$loess
```

```{r}

cocor::cocor(~ `content_trust_combined_score` + `author_trust_combined_score` | `content_trust_combined_score` + `author_trust_combined_score`,

      data = list(

        as.data.frame(s1_cleaned_data |> filter(Condition == "High")),

        as.data.frame(s1_cleaned_data |> filter(Condition == "Low"))

      )

)

cocor::cocor(~ `content_trust_combined_score` + `author_trust_combined_score` | `content_trust_combined_score` + `author_trust_combined_score`,

      data = list(

        as.data.frame(s1_cleaned_data |> filter(Condition == "High")),

        as.data.frame(s1_cleaned_data |> filter(Condition == "Medium"))

      )

)

cocor::cocor(~ `content_trust_combined_score` + `author_trust_combined_score` | `content_trust_combined_score` + `author_trust_combined_score`,

      data = list(

        as.data.frame(s1_cleaned_data |> filter(Condition == "Low")),

        as.data.frame(s1_cleaned_data |> filter(Condition == "Medium"))

      )

)

```

##### Partial correlations


```{r}

```

What is the relationship between anthropomorphism and author trust, when controlling for content trust?


```{r}

s1_cleaned_data |> partial_correlation_test("anthropomorphism_score", "author_trust_combined_score", "content_trust_combined_score")
```

What is the breakdown by Condition?

```{r}
s1_cleaned_data |> filter(Condition == "Low") |> partial_correlation_test("anthropomorphism_score", "author_trust_combined_score", "content_trust_combined_score")

s1_cleaned_data |> filter(Condition == "Medium") |> partial_correlation_test("anthropomorphism_score", "author_trust_combined_score", "content_trust_combined_score")

s1_cleaned_data |> filter(Condition == "High") |> partial_correlation_test("anthropomorphism_score", "author_trust_combined_score", "content_trust_combined_score")
```


What is the relationship between anthropomorphism and content trust, when controlling for author trust?

```{r}

s1_cleaned_data |> partial_correlation_test("anthropomorphism_score", "content_trust_combined_score", "author_trust_combined_score")

```

What is the breakdown by Condition?

```{r}
s1_cleaned_data |> filter(Condition == "Low") |> partial_correlation_test("anthropomorphism_score", "content_trust_combined_score", "author_trust_combined_score")

s1_cleaned_data |> filter(Condition == "Medium") |> partial_correlation_test("anthropomorphism_score", "content_trust_combined_score", "author_trust_combined_score")

s1_cleaned_data |> filter(Condition == "High") |> partial_correlation_test("anthropomorphism_score", "content_trust_combined_score", "author_trust_combined_score")
```



Bar plot: raw vs partial correlations (with stars)

```{r}

plot_corr_vs_partial_bars(
  s1_cleaned_data,
  x = "anthropomorphism_score",
  y = "author_trust_combined_score",
  z = "content_trust_combined_score",
  x_label = "anthro",
  y_label = "author",
  z_label = "content"
)

```

```{r}
plot_corr_vs_partial_bars(
  s1_cleaned_data |> filter(Condition == "Low"),
  x = "anthropomorphism_score",
  y = "author_trust_combined_score",
  z = "content_trust_combined_score",
  x_label = "anthro",
  y_label = "author",
  z_label = "content"
)
```

```{r}
plot_corr_vs_partial_bars(
  s1_cleaned_data |> filter(Condition == "Medium"),
  x = "anthropomorphism_score",
  y = "author_trust_combined_score",
  z = "content_trust_combined_score",
  x_label = "anthro",
  y_label = "author",
  z_label = "content"
)
```

```{r}
plot_corr_vs_partial_bars(
  s1_cleaned_data |> filter(Condition == "High"),
  x = "anthropomorphism_score",
  y = "author_trust_combined_score",
  z = "content_trust_combined_score",
  x_label = "anthro",
  y_label = "author",
  z_label = "content"
)
```


# References

```{r}
my_packages = c("rstatix", "stats", "effectsize", "psych", "interactions",
                 "corrplot", "performance", "FSA", "see")

write_bib(my_packages, file= "outputs/s1/packages.bib")
```
