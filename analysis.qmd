---
title: "Analysis"
author: "Caroline Simpson"
format: 
  html:
    theme: cerulean
    df-print: kable
    code-fold: false
    toc: true
    toc-float:
      collapsed: true
      smooth-scroll: false
    toc-depth: 7

editor: visual
---

```{r include=FALSE}

library(knitr)
library(kableExtra)
# library(rstatix)
library(tidyverse)
# library(forcats)
# # library(qualtRics)
# library(haven)
# library(jtools)
# library(forcats)
# library(FactoMineR)
# library(psych)
# library(interactions)
# library(corrplot)
# library(rcartocolor)
# library(ggpubr)
# library(ggtext)
# library(ggsignif)
# library(apaTables)
# 
# library(FSA)
# 
# library(performance)
# library(see)


source("./scripts/data-loading.R", local = TRUE)
source("./scripts/data-cleaning.R", local = TRUE)
source("./scripts/analysis-data-properties.R", local = TRUE)
source("./scripts/analysis-descriptives.R", local = TRUE)
source("./scripts/analysis-reliability.R", local = TRUE)
source("./scripts/analysis-inferential.R", local = TRUE)
source("./scripts/analysis-correlation.R", local = TRUE)
source("./scripts/plotting.R", local = TRUE)
source("./scripts/common.R", local = TRUE)
# source("./helpers.R", local = TRUE)

directory_setup()
theme_set(my_theme)


```


# Trusting the machine: Epistemic trust and anthropomorphism in generative artificial intelligence

**Research Question**: What effect does anthropomorphism have on level of trust in generative AI and the content it creates?

My **hypothesis** is that there will be an increase in epistemic trust with increasing levels of anthropomorphism.

## Highlights

-   Anthropomorphism manipulation did not work as expected. No significant difference in Anthropomorphism ratings between Low and Medium conditions.

    -   All of Anthropomorphism, Likeability, Competence, Expertise, Integrity, and Benevolence showed the same patterns of variance.

-   No significant difference in Trust ratings for the Content based on Anthropomorphism condition

-   Main effect of AI Usage Frequency on Content Trust. Significant difference between those that rarely use AI (lower trust) and those that frequently use it, and those that rarely use it and occasional users. No difference between frequent and occasional users. \[ This is based on the regrouped frequencies, the more granular raw data was less straightforward to interpret. \]

    -   Interaction effect with AI Usage Frequency and Condition. Significant difference between High and Medium, and High and Low for occasional users only.

-   Main effect of Science Content Consumption Frequency on Content Trust. Significant difference between those that rarely consume science content (lower trust) than frequent or occasional consumers of such content. (No interaction with anthropomorphism condition.)

-   Main effect of Intention to Use AI in the future on Content Trust. Positive correlation. (No interaction with anthropomorphism condition.)

-   Main effect on Content Trust for rating of "Well-written". Perception of more well-written correlates to higher Content Trust.

-   Main effect on Content Trust for rating of "Boring". Perception of less boring correlates to higher Content Trust.

-   Main effect on Content Trust for rating of "Engaging". Perception of more engaging correlates to higher Content Trust.

-   Main effect of the Survey Purpose check response. Those that stated being unsure of the purpose of the survey had lower trust in the content than those that gave a purpose either related to AI or not. (No interaction with anthropomorphism condition.)

-   No significant difference in Content Trust among those that found something unbelievable in the survey compared to those that did not

-   Main effect of Condition on Author Trust. Significant difference between High and Medium comparison and High and Low (with higher trust for High condition in both cases). No significant difference between Low and Medium.

-   Author trust very highly correlated to expertise, integrity, benevolence, competence, and likeability (with likeability being the lowest at .9). The correlations for Content trust are much lower with author competence and expertise being the lowest at 0.69. (This is across all data.) These vary by Condition (I have not checked if the difference is significant yet).

-   Main effect of perceived unrealistic reason on Author Trust (p = 0.04). When I did pairwise t-tests no significant results. (closest would be "Description Not Believable", but these all have small n). When I look at the LM there are significant values for "Description Not Believable".

-   Main effect on Author Trust for rating of "Well-written". Perception of more well-written correlates to higher Author Trust.

-   Main effect on Author Trust for rating of "Boring". Perception of less boring correlates to higher Author Trust.

-   Main effect on Author Trust for rating of "Engaging". Perception of more engaging correlates to higher Author Trust.

-   Additionally, main effects of changed opinion of ai based on study experience, fear of AI rating, belief they could write the content on Content Trust and Author Trust, but need to look at this data more still to verify. No effect of professional writing or content area expertise on Content Trust and Author Trust.

-   

## Next Steps

-   Look at correlation between anthropomorphism and trust scores ignoring groups

-   Address anthropomorphism manipulation not working?

-   Replication of Author vs Content trust discrepancy?

## Data Analysis

### Load data


```{r}
s1_raw_data <- load_data("s1")
s1_raw_data <- factorize_data("s1", s1_raw_data)
```

Number of participants in raw data = `r nrow(s1_raw_data)`.

```{r}

s1_raw_data <- explode_chatbots_used(s1_raw_data)

s1_raw_data <- explode_languages(s1_raw_data)

```

```{r}
s1_raw_data <- exclude_non_consenting_participants(s1_raw_data)
```


### Manual Processing

Reviewed and coded Survey purpose check (what they think this study is about, not the attention check)

-   Manually coded the response values with the following key:

    -   0 = no answer provided

    -   1 = identified the survey was about AI content, perception of AI, human versus AI distinction

    -   2 = nonsensical text

    -   3 = values that describe a purpose

    -   4 = random word

    -   5 = unsure

    -   6 = "the study was interesting" or "good" and variations of this

    -   7 = None

```{r}
summarize_columns(s1_raw_data, SurveyTopicCheck_coded)
```

Reviewed and coded Unrealistic parts of survey.

-   Unrealistic field is a separate field with the values of:

    -   1 = No

    -   2 = Yes

-   Unrealistic_coded -\> Manually coded the response values from Unrealistic_2_TEXT field with the following key:

    -   0 = no answer provided

    -   1 = believe descriptions written by AI or content written by AI when told human or content written by human when told AI

    -   2 = don't believe that traits make sense to apply to AI

    -   3 = it all seemed realistic

    -   4 = description of AI was not believable

    -   5 = random text

    -   6 = unsure why they were asked questions about AI (in High condition)

```{r}

s1_raw_data |> summarize_columns(Unrealistic)

s1_raw_data |> summarize_columns(Unrealistic, Unrealistic_coded) 
```

### Clean Data

No ability to check for duplicates because we recruited through CloudResearch and don't have ids. Assume that the platform prevents duplicate participant responses. 


```{r}
recruited_participants <- s1_raw_data |> count_recruited_participants("s1")
```

Number of participants recruited = `r recruited_participants`.

```{r}
s1_cleaned_data <- s1_raw_data |> clean_data("s1")

```

Number of participants after basic filtering = `r nrow(s1_cleaned_data)`.

### Fill missing values

#### Assess skewness and distribution

```{r}

# Compute skewness for each numeric variable
s1_cleaned_data |> check_skewness("s1")

# Shapiro-Wilk normality test 
s1_cleaned_data |>
  select(-Progress, -ConsentForm, -`Duration (in seconds)`, -Status, -Finished, -TopicCheck, -GodspeedMETI_28, -GodspeedMETI_29, -AIChatbotsUsed_NA, -Reread, -LanguagesFluent_NA) |> check_normality("s1")

```

#### Fill missing values with median values

Populate missing values with the median within Condition.

```{r}

missing_values_within_conditions(s1_cleaned_data)

# Perform imputation only on selected variables
s1_imputed_data <- impute_data(s1_cleaned_data)

missing_values_within_conditions(s1_imputed_data)

```

### Reverse Coding

Reverse code items for each scale where appropriate

```{r}
s1_recoded_data <- s1_imputed_data |> recode_data("s1")
```

#### Standardize Scale Item Values

```{r}

s1_cleaned_data <- s1_recoded_data |> standardize_data()

```

#### Regroup data

Regroup the AIChatbotsFrequency, Education, and Age columns into smaller number of categories of data for analysis. Some of the more granular categories don't have a large enough sample for meaningful comparisons.

```{r}

s1_cleaned_data <- s1_cleaned_data |> regroup_data()

```

### Calculate Scale Scores

#### Define Score Components

-   Calculate scores for Content Trust, Author Trust, Anthropomorphism, Likeability, Competence, Expertise, Integrity, Benevolence

```{r}

s1_cleaned_data <- s1_cleaned_data |> compute_scores("s1")

```


### Scale Inter-item Reliability Analysis

#### Anthropomorphism (Godspeed Subscale)

```{r}

basic_descriptives(s1_cleaned_data$anthropomorphism_score)

s1_cleaned_data |> cronbachs_alpha(get_anthropomorphism_score_godspeed_cols())

```

#### Likeability (Godspeed Subscale)

```{r}

basic_descriptives(s1_cleaned_data$likeability_score)

s1_cleaned_data |> cronbachs_alpha(get_likeability_score_godspeed_cols())

```

#### Competence (Godspeed Subscale)

```{r}

basic_descriptives(s1_cleaned_data$competence_score)

s1_cleaned_data |> cronbachs_alpha(get_competence_score_godspeed_cols())

```

#### Expertise (METI Subscale)

```{r}

basic_descriptives(s1_cleaned_data$expertise_score)

s1_cleaned_data |> cronbachs_alpha(get_expertise_score_METI_cols())

```

#### Integrity (METI Subscale)

```{r}

basic_descriptives(s1_cleaned_data$integrity_score)

s1_cleaned_data |> cronbachs_alpha(get_integrity_score_METI_cols())


```

#### Benevolence (METI Subscale)

```{r}
basic_descriptives(s1_cleaned_data$benevolence_score)

s1_cleaned_data |> cronbachs_alpha(get_benevolence_score_METI_cols())

```

#### METI (Author Trust)

```{r}

basic_descriptives(s1_cleaned_data$author_trust_METI_score)

s1_cleaned_data |> cronbachs_alpha(get_author_trust_score_METI_cols())

```

#### Trust Behaviour (Author Trust)

```{r}
basic_descriptives(s1_cleaned_data$author_trust_behaviour_score)

s1_cleaned_data |> cronbachs_alpha(get_author_trust_score_behaviour_cols("s1"))

```

#### Combine Author Trust

```{r}

basic_descriptives(s1_cleaned_data$author_trust_combined_score)

s1_cleaned_data |> cronbachs_alpha(get_author_trust_score_combined_cols("s1"))


```

#### Appelman (Content Trust)

```{r}
basic_descriptives(s1_cleaned_data$content_trust_appelman_score)

s1_cleaned_data |> cronbachs_alpha(get_content_trust_score_appelman_cols())

```

#### Trust Behaviour (Content Trust)

```{r}
basic_descriptives(s1_cleaned_data$content_trust_behaviour_score)

s1_cleaned_data |> cronbachs_alpha(get_content_trust_score_behaviour_cols())

```

#### Combined Content Trust

```{r}

basic_descriptives(s1_cleaned_data$content_trust_combined_score)

s1_cleaned_data |> cronbachs_alpha(get_content_trust_score_combined_cols())

```

#### Expertise / Intentions

```{r}
basic_descriptives(s1_cleaned_data$intention_to_use_score)
s1_cleaned_data |> cronbachs_alpha(get_intention_cols())


basic_descriptives(s1_cleaned_data$fear_of_ai_score)
s1_cleaned_data |> cronbachs_alpha(get_fear_cols())


basic_descriptives(s1_cleaned_data$professional_content_expertise)
s1_cleaned_data |> cronbachs_alpha(get_participant_expertise_cols())

```



### Sample Characteristics

```         
N=`r length(unique(s1_cleaned_data$ResponseId))`
```

#### Study duration (in minutes)


```{r}
basic_descriptives(s1_cleaned_data$`Duration (in seconds)` / 60)
```

#### Participants reporting Technical Issues (Not removed in data cleaning)

```{r}
s1_cleaned_data |> 
  summarize_columns(TechnicalIssues) 

```

```{r}
s1_cleaned_data |> 
  summarize_columns(Unrealistic_coded) 
```

#### Participants per condition.

```{r}
s1_cleaned_data |> 
  summarize_columns(Condition)

```

#### Age

```         
Age range: `r round(min(s1_cleaned_data$Age_1, na.rm = TRUE), 2)` to `r round(max(s1_cleaned_data$Age_1, na.rm = TRUE), 2)`
Mean age: `r round(mean(s1_cleaned_data$Age_1, na.rm = TRUE), 2)`
Standard deviation: `r round(sd(s1_cleaned_data$Age_1, na.rm = TRUE), 2)`
```

```{r}
s1_cleaned_data |> 
  summarize_columns(age_range)

s1_cleaned_data |> 
  summarize_columns(age_range, Condition) 
```

#### Gender

```{r}

s1_cleaned_data |> 
  summarize_columns(Gender) 

s1_cleaned_data |> 
  summarize_columns(Gender, Condition) 

```

#### Sex

```{r}

s1_cleaned_data |> 
  summarize_columns(Sex)

s1_cleaned_data |> 
  summarize_columns(Sex, Condition)
```

#### Education Level

```{r}

s1_cleaned_data |> 
  summarize_columns(Education) 

s1_cleaned_data |> 
  summarize_columns(Education, Condition) 

s1_cleaned_data |> 
  summarize_columns(Education_regrouped) 

s1_cleaned_data |> 
  summarize_columns(Education_regrouped, Condition) 

```

#### AI Chatbot Usage

```{r}

s1_cleaned_data |> 
  summarize_columns(AIChatbotsFrequency) 

s1_cleaned_data |> 
  summarize_columns(AIChatbotsFrequency, Condition) 

s1_cleaned_data |> 
  summarize_columns(AIChatbotsFrequency_regrouped) 

s1_cleaned_data |> 
  summarize_columns(AIChatbotsFrequency_regrouped, Condition) 

s1_cleaned_data |> summarize_exploded_columns("AIChatbotsUsed", AIChatbotsUsed)
  
s1_cleaned_data |> summarize_exploded_columns("AIChatbotsUsed", AIChatbotsUsed, Condition)

```

#### Science Content Familiarity

```{r}

s1_cleaned_data |> 
  summarize_columns(ScienceContent) 

s1_cleaned_data |> 
  summarize_columns(ScienceContent, Condition) 

s1_cleaned_data |> 
  summarize_columns(ScienceContent_regrouped) 

s1_cleaned_data |> 
  summarize_columns(ScienceContent_regrouped, Condition) 

```

#### Expertise

```{r}

s1_cleaned_data |> 
  summarize_columns(intention_to_use_score) 

s1_cleaned_data |> 
  summarize_columns(intention_to_use_score, Condition) 

s1_cleaned_data |> 
  summarize_columns(fear_of_ai_score) 

s1_cleaned_data |> 
  summarize_columns(fear_of_ai_score, Condition) 

s1_cleaned_data |> 
  summarize_columns(professional_content_expertise)

s1_cleaned_data |> 
  summarize_columns(professional_content_expertise, Condition) 

# changed opinion of AI
s1_cleaned_data |> 
  summarize_columns(Experience_4) 

s1_cleaned_data |> 
  summarize_columns(Experience_4, Condition) 


s1_cleaned_data |> 
  summarize_columns(Experience_7) 

s1_cleaned_data |> 
  summarize_columns(Experience_7, Condition) 


```

#### English as a First Language

```{r}

s1_cleaned_data |> 
  summarize_columns(English) 

s1_cleaned_data |> 
  summarize_columns(English, Condition) 
```

#### Other Languages

```{r}

s1_cleaned_data |> summarize_exploded_columns("LanguagesFluent", LanguagesFluent)

s1_cleaned_data |> summarize_exploded_columns("LanguagesFluent", LanguagesFluent, Condition)

```


### Manipulation Check

#### Anthropomorphism

We attempted to explicitly manipulated the level of anthropomorphism. Therefore, we would expect to see a significant difference in this score across the 3 conditions.

##### Plot

```{r}

violin_plot(s1_cleaned_data, 
            "s1",
            "Condition",
            "anthropomorphism_score",
            include_legend = FALSE)
```

##### Descriptive Statistics

```{r}
s1_cleaned_data |> descriptives_by_group(Condition, anthropomorphism_score) 
```

##### Inferential Statistics

###### ANOVA

```{r}
aov_model <- s1_cleaned_data |> run_between_subjects_anova(anthropomorphism_score ~ Condition, "anthropomorphism_score")

```

###### T-tests
```{r}
s1_cleaned_data |> run_simple_effects_t_tests(anthropomorphism_score ~ Condition)
```

#### Likeability

We were not explicitly intending to manipulate likeability

##### Plot

```{r}
violin_plot(s1_cleaned_data, 
            "s1",
            "Condition",
            "likeability_score",
            include_legend = FALSE)
```

##### Descriptive Statistics

```{r}
s1_cleaned_data |> descriptives_by_group(Condition, likeability_score) 
```

##### Inferential Statistics

###### ANOVA

```{r}
aov_model <- s1_cleaned_data |> run_between_subjects_anova(likeability_score ~ Condition, "likeability_score")

```

###### T-tests
```{r}
s1_cleaned_data |> run_simple_effects_t_tests(likeability_score ~ Condition)
```


#### Competence

We were not explicitly intending to manipulate competence
##### Plot

```{r}
violin_plot(s1_cleaned_data, 
            "s1",
            "Condition",
            "competence_score",
            include_legend = FALSE)
```

##### Descriptive Statistics

```{r}
s1_cleaned_data |> descriptives_by_group(Condition, competence_score) 
```

##### Inferential Statistics

###### ANOVA

```{r}
aov_model <- s1_cleaned_data |> run_between_subjects_anova(competence_score ~ Condition, "competence_score")

```

###### T-tests
```{r}
s1_cleaned_data |> run_simple_effects_t_tests(competence_score ~ Condition)
```


### Main Analysis

#### Content Trust

##### Plot

```{r}

plot <- violin_plot(s1_cleaned_data, 
            "s1",
            "Condition",
            "content_trust_combined_score",
            include_legend = FALSE)

plot
```

##### Descriptive Statistics

```{r}

s1_cleaned_data |> descriptives_by_group(Condition, content_trust_combined_score)

```

##### Inferential Statistics

###### ANOVA

```{r}
aov_model <- s1_cleaned_data |> run_between_subjects_anova(content_trust_combined_score ~ Condition, "competence_score")

```

###### T-tests
```{r}
s1_cleaned_data |> run_simple_effects_t_tests(content_trust_combined_score ~ Condition)
```


##### Post-hoc Analysis

###### Anthropomorphism

```{r}

s1_cleaned_data |> linear_model(content_trust_combined_score ~ anthropomorphism_score)
```

```{r}

s1_cleaned_data |> test_correlation("anthropomorphism_score", "content_trust_combined_score")

plot <- correlation_plot(s1_cleaned_data, 
            "s1",
            "anthropomorphism_score",
            "content_trust_combined_score")

plot
```

###### Author / Content Trust Interaction

```{r}

s1_cleaned_data |> test_correlation("author_trust_combined_score", "content_trust_combined_score")

plots <- correlation_plot(s1_cleaned_data, 
            "s1",
            "author_trust_combined_score",
            "content_trust_combined_score")

# Display the plots
plots$lm
plots$loess
```

```{r}


lm_model <- s1_cleaned_data |> linear_model(content_trust_combined_score ~  author_trust_combined_score * anthropomorphism_score)

plot <- s1_cleaned_data |> interaction_plot_3(
  lm_model, 
  pred_name = "author_trust_combined_score",
  mod_name = "anthropomorphism_score", 
  target_name = "content_trust_combined_score", 
  study = "s1")

plot


```

```{r}


lm_model <- s1_cleaned_data |> linear_model(content_trust_combined_score ~ anthropomorphism_score * author_trust_combined_score * AIChatbotsFrequency_regrouped)

plot <- s1_cleaned_data |> interaction_plot_4(
  lm_model, 
  pred_name = "author_trust_combined_score",
  mod_name = "anthropomorphism_score", 
  mod2_name = "AIChatbotsFrequency_regrouped",
  mod2_v = c("frequently", "occasionally", "rarely"),
  target_name = "content_trust_combined_score", 
  study = "s1")

plot

```



###### Age

```{r}

aov_model <- s1_cleaned_data |> run_between_subjects_anova(content_trust_combined_score ~ age_range, "content_trust_combined_score")

```


```{r}

s1_cleaned_data |> test_correlation("Age_1", "content_trust_combined_score")

plots <- correlation_plot(s1_cleaned_data, 
            "s1",
            "Age_1",
            "content_trust_combined_score")

# Display the plots
plots$lm
plots$loess

```

###### Gender

```{r}

aov_model <- s1_cleaned_data |>
  droplevels() |>
  run_between_subjects_anova(content_trust_combined_score ~ Gender, "content_trust_combined_score")

s1_cleaned_data |>
  droplevels() |> run_simple_effects_t_tests(content_trust_combined_score ~ Gender)


```




###### Sex

```{r}

aov_model <- s1_cleaned_data |>
  droplevels() |>
  run_between_subjects_anova(content_trust_combined_score ~ Sex, "content_trust_combined_score")

```


###### Education

```{r}

aov_model <- s1_cleaned_data |>
  droplevels() |>
  run_between_subjects_anova(content_trust_combined_score ~ Education_regrouped, "content_trust_combined_score")

```


###### AI Usage Experience

```{r}

aov_model <- s1_cleaned_data |>
  run_between_subjects_anova(content_trust_combined_score ~ AIChatbotsFrequency_regrouped, "content_trust_combined_score")

s1_cleaned_data |> run_simple_effects_t_tests(content_trust_combined_score ~ AIChatbotsFrequency_regrouped)

plot <- violin_plot(s1_cleaned_data, 
            "s1",
            "AIChatbotsFrequency_regrouped",
            "content_trust_combined_score",
            include_legend = FALSE, 
            comparisons = list(  c("rarely", "occasionally"),
    c("rarely", "frequently"),
    c("occasionally", "frequently") ))

plot

```



```{r}
lm_model <- s1_cleaned_data |> linear_model(content_trust_combined_score ~ Condition * AIChatbotsFrequency_regrouped)

plot <- s1_cleaned_data |>
  categorical_interaction_plot_3(lm_model,
                                pred_name = "Condition",
                                mod_name = "AIChatbotsFrequency_regrouped",
                                target_name = "content_trust_combined_score",
                                study = "s1"
                                )

plot

```

###### Science Content Experience

```{r}

aov_model <- s1_cleaned_data |>
  run_between_subjects_anova(content_trust_combined_score ~ ScienceContent_regrouped, "content_trust_combined_score")

s1_cleaned_data |> run_simple_effects_t_tests(content_trust_combined_score ~ ScienceContent_regrouped)

plot <- violin_plot(s1_cleaned_data, 
            "s1",
            "ScienceContent_regrouped",
            "content_trust_combined_score",
            include_legend = FALSE, 
            comparisons = list(  c("rarely", "occasionally"),
    c("rarely", "frequently"),
    c("occasionally", "frequently") ))

plot


```




```{r}

lm_model <- s1_cleaned_data |> linear_model(content_trust_combined_score ~ Condition * ScienceContent_regrouped)

plot <- s1_cleaned_data |>
  categorical_interaction_plot_3(lm_model,
                                pred_name = "Condition",
                                mod_name = "ScienceContent_regrouped",
                                target_name = "content_trust_combined_score",
                                study = "s1"
                                )

plot


```

###### Intention to Use AI

```{r}
s1_cleaned_data |> test_correlation("intention_to_use_score", "content_trust_combined_score")

plots <- correlation_plot(s1_cleaned_data, 
            "s1",
            "intention_to_use_score",
            "content_trust_combined_score")

# Display the plots
plots$lm
plots$loess


```

###### Changed Opinion

```{r}

s1_cleaned_data |> descriptives_by_group(Experience_4, content_trust_combined_score) 

aov_model <- s1_cleaned_data |>
  run_between_subjects_anova(content_trust_combined_score ~ Experience_4, "content_trust_combined_score")

s1_cleaned_data |> run_simple_effects_t_tests(content_trust_combined_score ~ Experience_4)

plot <- violin_plot(s1_cleaned_data,
            "s1",
            "Experience_4",
            "content_trust_combined_score",
            include_legend = FALSE,
            comparisons = list(  
              c("1", "2"),
              c("2", "3"),
              c("3", "4"),
              c("4", "5"),
              c("1", "3"),
              c("2", "4"),
              c("3", "5"),
              c("1", "4"),
              c("2", "5"),
              c("1", "5")
              )
    )

```


###### Fear of AI

```{r}


s1_cleaned_data |> test_correlation("fear_of_ai_score", "content_trust_combined_score")

plots <- correlation_plot(s1_cleaned_data, 
            "s1",
            "fear_of_ai_score",
            "content_trust_combined_score")

# Display the plots
plots$lm
plots$loess

```


###### Could Write

```{r}

s1_cleaned_data |> descriptives_by_group(Experience_7, content_trust_combined_score) 

aov_model <- s1_cleaned_data |>
  run_between_subjects_anova(content_trust_combined_score ~ Experience_7, "content_trust_combined_score")

s1_cleaned_data |> run_simple_effects_t_tests(content_trust_combined_score ~ Experience_7)

plot <- violin_plot(s1_cleaned_data,
            "s1",
            "Experience_7",
            "content_trust_combined_score",
            include_legend = FALSE,
            comparisons = list(  
              c("1", "2"),
              c("2", "3"),
              c("3", "4"),
              c("4", "5"),
              c("1", "3"),
              c("2", "4"),
              c("3", "5"),
              c("1", "4"),
              c("2", "5"),
              c("1", "5")
              )
    )

```


###### Professional Content / Writing Expertise

```{r}

s1_cleaned_data |> test_correlation("professional_content_expertise", "content_trust_combined_score")

plots <- correlation_plot(s1_cleaned_data, 
            "s1",
            "professional_content_expertise",
            "content_trust_combined_score")

# Display the plots
plots$lm
plots$loess

```

###### Content Properties

Well-written

```{r}
s1_cleaned_data |> descriptives_by_group(Appelman_4, content_trust_combined_score) 

aov_model <- s1_cleaned_data |>
  run_between_subjects_anova(content_trust_combined_score ~ Appelman_4, "content_trust_combined_score")

s1_cleaned_data |> run_simple_effects_t_tests(content_trust_combined_score ~ Appelman_4)

plot <- violin_plot(s1_cleaned_data,
            "s1",
            "Appelman_4",
            "content_trust_combined_score",
            include_legend = FALSE,
            comparisons = list(  
              c("-2", "-1"),
              c("-1", "0"),
              c("0", "1"),
              c("1", "2"),
              c("-2", "0"),
              c("-1", "1"),
              c("0", "2"),
              c("-2", "1"),
              c("-1", "2"),
              c("-2", "2")
              )
    )
```


```{r}

lm_model <- s1_cleaned_data |> linear_model(content_trust_combined_score ~ Condition * Appelman_4)

plot <- s1_cleaned_data |>
  categorical_interaction_plot_3(lm_model,
                                pred_name = "Condition",
                                mod_name = "Appelman_4",
                                target_name = "content_trust_combined_score",
                                study = "s1"
                                )

plot

```

Boring

```{r}
s1_cleaned_data |> descriptives_by_group(Appelman_5, content_trust_combined_score) 

aov_model <- s1_cleaned_data |>
  run_between_subjects_anova(content_trust_combined_score ~ Appelman_5, "content_trust_combined_score")

s1_cleaned_data |> run_simple_effects_t_tests(content_trust_combined_score ~ Appelman_5)

plot <- violin_plot(s1_cleaned_data,
            "s1",
            "Appelman_5",
            "content_trust_combined_score",
            include_legend = FALSE,
            comparisons = list(  
              c("-2", "-1"),
              c("-1", "0"),
              c("0", "1"),
              c("1", "2"),
              c("-2", "0"),
              c("-1", "1"),
              c("0", "2"),
              c("-2", "1"),
              c("-1", "2"),
              c("-2", "2")
              )
    )
```


```{r}

lm_model <- s1_cleaned_data |> linear_model(content_trust_combined_score ~ Condition * Appelman_5)

plot <- s1_cleaned_data |>
  categorical_interaction_plot_3(lm_model,
                                pred_name = "Condition",
                                mod_name = "Appelman_5",
                                target_name = "content_trust_combined_score",
                                study = "s1"
                                )

plot

```



Engaging

```{r}
s1_cleaned_data |> descriptives_by_group(Appelman_6, content_trust_combined_score) 

aov_model <- s1_cleaned_data |>
  run_between_subjects_anova(content_trust_combined_score ~ Appelman_6, "content_trust_combined_score")

s1_cleaned_data |> run_simple_effects_t_tests(content_trust_combined_score ~ Appelman_6)

plot <- violin_plot(s1_cleaned_data,
            "s1",
            "Appelman_6",
            "content_trust_combined_score",
            include_legend = FALSE,
            comparisons = list(  
              c("-2", "-1"),
              c("-1", "0"),
              c("0", "1"),
              c("1", "2"),
              c("-2", "0"),
              c("-1", "1"),
              c("0", "2"),
              c("-2", "1"),
              c("-1", "2"),
              c("-2", "2")
              )
    )
```


```{r}

lm_model <- s1_cleaned_data |> linear_model(content_trust_combined_score ~ Condition * Appelman_6)

plot <- s1_cleaned_data |>
  categorical_interaction_plot_3(lm_model,
                                pred_name = "Condition",
                                mod_name = "Appelman_6",
                                target_name = "content_trust_combined_score",
                                study = "s1"
                                )

plot

```



###### Survey Purpose Check


```{r}
s1_cleaned_data |> descriptives_by_group(SurveyTopicCheck_coded, content_trust_combined_score) 

aov_model <- s1_cleaned_data |>
  run_between_subjects_anova(content_trust_combined_score ~ SurveyTopicCheck_coded, "content_trust_combined_score")

# s1_cleaned_data |> 
#   droplevels() |> 
#   run_simple_effects_t_tests(content_trust_combined_score ~ SurveyTopicCheck_coded)
# 
# plot <- violin_plot(s1_cleaned_data,
#             "s1",
#             "SurveyTopicCheck_coded",
#             "content_trust_combined_score",
#             include_legend = FALSE,
#             comparisons = list( 
#               c("AI", "Unsure"),
#               c("Non-AI Purpose", "Unsure")
#               )
#     )
```

###### Unrealistic Check

```{r}
s1_cleaned_data |> descriptives_by_group(Unrealistic, content_trust_combined_score) 

aov_model <- s1_cleaned_data |>
  run_between_subjects_anova(content_trust_combined_score ~ Unrealistic, "content_trust_combined_score")

```

```{r}
s1_cleaned_data |> descriptives_by_group(Unrealistic_coded, content_trust_combined_score) 

aov_model <- s1_cleaned_data |>
   group_by(Unrealistic_coded) |> filter(n() > 3) |> ungroup() |>
  run_between_subjects_anova(content_trust_combined_score ~ Unrealistic_coded, "content_trust_combined_score")

s1_cleaned_data |>
  droplevels() |>
  run_simple_effects_t_tests(content_trust_combined_score ~ Unrealistic_coded)


```


#### Author Trust

##### Plot

```{r}
plot <- violin_plot(s1_cleaned_data, s1_cleaned_data$Condition, s1_cleaned_data$author_trust_combined_score, s1_cleaned_data$Condition, "Author Trust Scores", x_label = "Anthropomorphism Condition", y_label = "Author Trust Score", comparisons = anthropomorphism_comparisons)

ggsave("plots/s1/author_anthropomorphism_distribution.png", plot = plot, create.dir = TRUE)

plot
```

##### Descriptive Statistics

```{r}
s1_cleaned_data |>
  select(Condition, author_trust_combined_score) |>
by(s1_cleaned_data$Condition, summary)

```

###### Standard Deviation

```{r}
tapply(s1_cleaned_data$author_trust_combined_score, s1_cleaned_data$Condition, sd)
```

###### Variance

```{r}
tapply(s1_cleaned_data$author_trust_combined_score, s1_cleaned_data$Condition, var)
```

##### Inferential Statistics

###### Main Effect ANOVA

```{r include=FALSE}

data <- s1_cleaned_data |> group_by(Condition) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Condition
x <- s1_cleaned_data$Condition
x_label <- "Anthropomorphism Condition"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

##### Post-hoc Analysis

###### Anthropomorphism

```{r}

fit_i <- lm(author_trust_combined_score ~ anthropomorphism_score , data = s1_cleaned_data)

summ(fit_i)

```

```{r}

cor_result <- cor.test(s1_cleaned_data$anthropomorphism_score, s1_cleaned_data$author_trust_combined_score, method = "pearson")
apa::cor_apa(cor_result, r_ci = TRUE)

```

```{r}
df <- s1_cleaned_data |>
  select(content_trust_combined_score, author_trust_combined_score, anthropomorphism_score)

```

```{r}
cor(df)
corrplot(cor(df),
         method = "number",
  sig.level = 0.05,
  type = "upper", # show only upper side
)

# 
# cat_plot(fit_i, pred = Condition, modx = age_range,  geom = "bar", colors = safe_pal)

```

```{r}
plot <- s1_cleaned_data |>
  ggplot(aes(x = anthropomorphism_score, y = author_trust_combined_score)) +
  labs(x="Anthropomorphism Score", y = "Author Trust Score")  +
  geom_point(col = "#196389", size = 0.5) +
        stat_smooth(method = "lm", formula = "y ~ x",
        col = "#7F2543", se = FALSE, size = 1
)

ggsave("plots/s1/author_anthropomorphism_correlation.png", plot = plot, create.dir = TRUE)

plot
```

###### Anthro / Author Trust Interaction

```{r}

lm_model <- lm(author_trust_combined_score ~ anthropomorphism_score * content_trust_combined_score, data = s1_cleaned_data)
summary(lm_model)

plot <- interact_plot(lm_model, 
              pred = anthropomorphism_score, 
              modx = content_trust_combined_score,  
              x.label ="Anthropomorphism Score",
              y.label = "Author Trust Score",
              legend.main = "Content Trust Score",
              plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", 
              colors = safe_pal) +
  theme(legend.position = "right")

ggsave("plots/s1/author_anthropomorphism_content_interaction.png", plot = plot, create.dir = TRUE)

plot

```

```{r}

lm_model <- lm(author_trust_combined_score ~ anthropomorphism_score * content_trust_combined_score * AIChatbotsFrequency_regrouped, data = s1_cleaned_data)
summary(lm_model)

plot <- interact_plot(lm_model, 
              pred = anthropomorphism_score, 
              modx = content_trust_combined_score,
              mod2 = AIChatbotsFrequency_regrouped,
              x.label ="Anthropomorphism Score",
              y.label = "Author Trust Score",
              legend.main = "Content Trust Score",
              mod2.values = c("frequently", "occasionally", "rarely"),
              mod2.labels = c("frequently", "occasionally", "rarely"),
              plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", 
              colors = safe_pal) +
  theme(legend.position = "right")

ggsave("plots/s1/author_anthropomorphism_content_frequency_interaction.png", plot = plot, create.dir = TRUE)

plot

```

```{r}

lm_model <- lm(author_trust_combined_score ~ anthropomorphism_score * AIChatbotsFrequency_regrouped, data = s1_cleaned_data)
summary(lm_model)

plot <- interact_plot(lm_model, 
              pred = anthropomorphism_score, 
              modx = AIChatbotsFrequency_regrouped,
              x.label ="Anthropomorphism Score",
              y.label = "Author Trust Score",
              legend.main = "Frequency",
              # mod2.values = c("frequently", "occasionally", "rarely"),
              # mod2.labels = c("frequently", "occasionally", "rarely"),
              plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", 
              colors = safe_pal) +
  theme(legend.position = "right")

ggsave("plots/s1/author_anthropomorphism_frequency_interaction.png", plot = plot, create.dir = TRUE)

plot

```

###### Age

```{r}
cor_result <- cor.test(s1_cleaned_data$author_trust_combined_score, s1_cleaned_data$Age_1, method = "pearson")
apa::cor_apa(cor_result, r_ci = TRUE)

s1_cleaned_data |>
  ggplot(aes(x = Age_1, y = author_trust_combined_score)) +
  geom_point() +
        stat_smooth(method = "lm",
        col = "#C42126", se = FALSE, size = 1
)
```

```{r}

data <- s1_cleaned_data |> group_by(age_range) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ age_range
x <- s1_cleaned_data$age_range
x_label <- "Age range"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

###### Age / Condition Interaction

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * age_range, data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = age_range,  geom = "bar", colors = safe_pal)
```

###### Gender (Man / Woman only)

```{r}

data <- s1_cleaned_data |> group_by(Gender) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Gender
x <- s1_cleaned_data$Gender
x_label <- "Gender"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

###### Gender / Condition Interaction

```{r}


fit_i <- lm(author_trust_combined_score ~ Condition * Gender, 
                    data = s1_cleaned_data |> filter(Gender == "Man" | Gender == "Woman"))

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Gender,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="line", colors = safe_pal)

```

###### Sex (Male / Female only)

```{r}

data <- s1_cleaned_data |> group_by(Sex) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Sex
x <- s1_cleaned_data$Sex
x_label <- "Sex"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

###### Sex / Condition Interaction

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Sex, 
                    data = s1_cleaned_data |> filter(Sex == "Male" | Sex == "Female"))

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Sex,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="line", colors = safe_pal)
```

###### Education

```{r}

data <- s1_cleaned_data |> group_by(Education) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Education
x <- s1_cleaned_data$Education
x_label <- "Education"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

```{r}

data <- s1_cleaned_data |> group_by(Education_regrouped) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Education_regrouped
x <- s1_cleaned_data$Education_regrouped
x_label <- "Education"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

###### Education / Condition Interaction

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Education, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Education,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)

fit_i <- lm(author_trust_combined_score ~ Condition * Education_regrouped, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Education_regrouped,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)

```

###### AI Usage Experience

```{r}
violin_plot(data = s1_cleaned_data, 
            x = s1_cleaned_data$AIChatbotsFrequency_regrouped, 
            y = s1_cleaned_data$author_trust_combined_score, 
            group = s1_cleaned_data$AIChatbotsFrequency_regrouped, 
            title = "Author Trust Scores by AI Usage Frequency", 
            legend_label = "AI Usage Frequency", 
            y_label = "Author Trust Score", x_label = "AI Usage Frequency")
```

```{r}

# frequency_comparisons <- list(  c("rarely", "occasionally"),
#     c("rarely", "frequently"),
#     c("occasionally", "frequently") )
# 
# condition_comparisons <- list(  c("High", "Medium"),
#     c("High", "Low"),
#     c("Medium", "Low") )
# 
# # Global test
# compare_means(author_trust_combined_score ~ AIChatbotsFrequency_regrouped,  data = s1_cleaned_data, method = "anova")
# 
# compare_means(author_trust_combined_score ~ AIChatbotsFrequency_regrouped, comparisons = frequency_comparisons, data = s1_cleaned_data,  method = "t.test")
# 
# 
# ggboxplot(s1_cleaned_data, x = "AIChatbotsFrequency_regrouped", y = "author_trust_combined_score",
#           color = "AIChatbotsFrequency_regrouped", palette = safe_pal)+ 
#   stat_compare_means(comparisons = frequency_comparisons, method = "t.test", label = "p.signif") + # Add pairwise comparisons p-value
#   stat_compare_means(label.y = 12, method = "anova")        +     # Add global p-value
#   ggtitle("Mean Author Trust by Frequency of AI Chatbot Use") + 
#     labs(x="Frequency of Use", y = "Author Trust", fill = "Frequency of Use")
#   
# 
# ggbarplot(s1_cleaned_data, x = "AIChatbotsFrequency_regrouped", y = "author_trust_combined_score",
#           add = "mean_sd",        
#           color = "AIChatbotsFrequency_regrouped", palette = safe_pal, position = position_dodge(0.8))+ 
#   stat_compare_means(comparisons = frequency_comparisons, method = "t.test", label = "p.signif") + # Add pairwise comparisons p-value
#   stat_compare_means(label.y = 12, method = "anova")      +     # Add global p-value
#   ggtitle("Mean Author Trust by Frequency of AI Chatbot Use") + 
#     labs(x="Frequency of Use", y = "Author Trust", fill = "Frequency of Use")
#   
# 
# ggbarplot(s1_cleaned_data |> filter(AIChatbotsFrequency_regrouped == "frequently"), x = "Condition", y = "author_trust_combined_score",
#           add = "mean_sd",        
#           color = "Condition", palette = safe_pal, position = position_dodge(0.8))+ 
#   stat_compare_means(comparisons = condition_comparisons, method = "t.test", label = "p.signif") +
#   stat_compare_means(label.y = 12, method = "anova")  +     # Add global p-value
#   ggtitle("Mean Author Trust by Condition for Frequent Users of AI Chatbots") + 
#     labs(x="Antropomorphism Condition", y = "Author Trust", fill = "Antropomorphism Condition")
#   
# 
# ggbarplot(s1_cleaned_data |> filter(AIChatbotsFrequency_regrouped == "occasionally"), x = "Condition", y = "author_trust_combined_score",
#           add = "mean_sd",        
#           color = "Condition", palette = safe_pal, position = position_dodge(0.8))+ 
#   stat_compare_means(comparisons = condition_comparisons, method = "t.test", label = "p.signif") +
#   stat_compare_means(label.y = 12, method = "anova")  +     # Add global p-value
#   ggtitle("Mean Author Trust by Condition for Occassional Users of AI Chatbots") + 
#     labs(x="Antropomorphism Condition", y = "Author Trust", fill = "Antropomorphism Condition")
#   
# ggbarplot(s1_cleaned_data |> filter(AIChatbotsFrequency_regrouped == "rarely"), x = "Condition", y = "author_trust_combined_score",
#           add = "mean_sd",        
#           color = "Condition", palette = safe_pal, position = position_dodge(0.8))+ 
#   stat_compare_means(comparisons = condition_comparisons, method = "t.test", label = "p.signif") +
#   stat_compare_means(label.y = 12, method = "anova") +     # Add global p-value
#   ggtitle("Mean Author Trust by Condition for Rare Users of AI Chatbots") + 
#     labs(x="Antropomorphism Condition", y = "Author Trust", fill = "Antropomorphism Condition")
  
```

```{r}

data <- s1_cleaned_data |> group_by(AIChatbotsFrequency_regrouped) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ AIChatbotsFrequency_regrouped 
x <- s1_cleaned_data$AIChatbotsFrequency_regrouped
x_label <- "AI Usage Frequency"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * AIChatbotsFrequency, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = AIChatbotsFrequency,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * AIChatbotsFrequency_regrouped,
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = AIChatbotsFrequency_regrouped,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)

```

###### Science Content Experience

```{r}

data <- s1_cleaned_data |> group_by(ScienceContent) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ ScienceContent
x <- s1_cleaned_data$ScienceContent
x_label <- "Science Content Consumption Frequency"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

```{r}

data <- s1_cleaned_data |> group_by(ScienceContent_regrouped) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ ScienceContent_regrouped
x <- s1_cleaned_data$ScienceContent_regrouped
x_label <- "Science Content Consumption Frequency"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

```{r}

# aov_model <- aov(author_trust_combined_score ~ ScienceContent, data = s1_cleaned_data)
# 
# par(mfrow = c(2, 2))
# plot(aov_model)
# 
# summary(aov_model)

fit_i <- lm(author_trust_combined_score ~ Condition * ScienceContent, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = ScienceContent,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)

fit_i <- lm(author_trust_combined_score ~ Condition * ScienceContent_regrouped, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = ScienceContent_regrouped,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)

```

###### Intention to Use AI

```{r}
cor_result <- cor.test(s1_cleaned_data$author_trust_combined_score, s1_cleaned_data$intention_to_use_score, method = "pearson")
apa::cor_apa(cor_result, r_ci = TRUE)

s1_cleaned_data |>
  ggplot(aes(x = intention_to_use_score, y = author_trust_combined_score)) +
  geom_point() +
        stat_smooth(method = "lm",
        col = "#C42126", se = FALSE, size = 1
)
```

```{r}
data <- s1_cleaned_data |> group_by(intention_to_use_score) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ intention_to_use_score
x <- s1_cleaned_data$intention_to_use_score
x_label <- "Intention to Use AI"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"


```

{{< include "_ANOVA.qmd" >}}

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * intention_to_use_score, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = intention_to_use_score,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

###### Changed Opinion

```{r}
cor_result <- cor.test(s1_cleaned_data$author_trust_combined_score, s1_cleaned_data$Experience_4, method = "pearson")
apa::cor_apa(cor_result, r_ci = TRUE)

s1_cleaned_data |>
  ggplot(aes(x = Experience_4, y = author_trust_combined_score)) +
  geom_point() +
        stat_smooth(method = "lm",
        col = "#C42126", se = FALSE, size = 1
)
```

```{r}
data <- s1_cleaned_data |> group_by(Experience_4) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Experience_4
x <- s1_cleaned_data$Experience_4
x_label <- "Study Changed Opinion of AI"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"


```

{{< include "_ANOVA.qmd" >}}

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Experience_4, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Experience_4,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

###### Fear of AI

```{r}
cor_result <- cor.test(s1_cleaned_data$author_trust_combined_score, s1_cleaned_data$fear_of_ai_score, method = "pearson")
apa::cor_apa(cor_result, r_ci = TRUE)

s1_cleaned_data |>
  ggplot(aes(x = fear_of_ai_score, y = author_trust_combined_score)) +
  geom_point() +
        stat_smooth(method = "lm",
        col = "#C42126", se = FALSE, size = 1
)
```

```{r}
data <- s1_cleaned_data |> group_by(fear_of_ai_score) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ fear_of_ai_score
x <- s1_cleaned_data$fear_of_ai_score
x_label <- "Fear of AI"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"


```

{{< include "_ANOVA.qmd" >}}

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * fear_of_ai_score, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = fear_of_ai_score,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

###### Could Write

```{r}
cor_result <- cor.test(s1_cleaned_data$author_trust_combined_score, s1_cleaned_data$Experience_7, method = "pearson")
apa::cor_apa(cor_result, r_ci = TRUE)

s1_cleaned_data |>
  ggplot(aes(x = Experience_7, y = author_trust_combined_score)) +
  geom_point() +
        stat_smooth(method = "lm",
        col = "#C42126", se = FALSE, size = 1
)
```

```{r}
data <- s1_cleaned_data |> group_by(Experience_7) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Experience_7
x <- s1_cleaned_data$Experience_7
x_label <- "Belief could write content"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"


```

{{< include "_ANOVA.qmd" >}}

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Experience_7, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Experience_7,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

###### Professional Content / Writing Expertise

```{r}
data <- s1_cleaned_data |> group_by(professional_content_expertise) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ professional_content_expertise
x <- s1_cleaned_data$professional_content_expertise
x_label <- "Professional Experience with Content or Writing"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"


```

{{< include "_ANOVA.qmd" >}}

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * professional_content_expertise, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = professional_content_expertise,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

###### Content Properties

Well-written

```{r}
cor_result <- cor.test(s1_cleaned_data$author_trust_combined_score, as.numeric(s1_cleaned_data$Appelman_4), method = "pearson")
apa::cor_apa(cor_result, r_ci = TRUE)

s1_cleaned_data |>
  ggplot(aes(x = Appelman_4, y = author_trust_combined_score)) +
  geom_point() +
        stat_smooth(method = "lm",
        col = "#C42126", se = FALSE, size = 1
)
```

```{r}
data <- s1_cleaned_data |> group_by(Appelman_4) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Appelman_4
x <- s1_cleaned_data$Appelman_4
x_label <- "Well-written"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"
```

{{< include "_ANOVA.qmd" >}}

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Appelman_4, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Appelman_4,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

Boring

```{r}
data <- s1_cleaned_data |> group_by(Appelman_5) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Appelman_5
x <- s1_cleaned_data$Appelman_5
x_label <- "Boring"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"
```

{{< include "_ANOVA.qmd" >}}

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Appelman_5, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Appelman_5,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

###### 

Engaging

```{r}
data <- s1_cleaned_data |> group_by(Appelman_6) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Appelman_6
x <- s1_cleaned_data$Appelman_6
x_label <- "Engaging"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"
```

{{< include "_ANOVA.qmd" >}}

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Appelman_6, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Appelman_6,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

###### Survey Purpose Check

```{r}

data <- s1_cleaned_data |> group_by(SurveyTopicCheck_coded) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ SurveyTopicCheck_coded
x <- s1_cleaned_data$SurveyTopicCheck_coded
x_label <- "Perceived Survey Purpose"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

Survey Purpose / Condition Interaction

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * SurveyTopicCheck_coded, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = SurveyTopicCheck_coded,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)
```

###### Unrealistic Check

```{r}

data <- s1_cleaned_data |> group_by(Unrealistic) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Unrealistic
x <- s1_cleaned_data$Unrealistic
x_label <- "Perceived Unrealistic"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

```{r}

data <- s1_cleaned_data |> group_by(Unrealistic_coded) |> filter(n() > 3) |> ungroup()
formula <- author_trust_combined_score ~ Unrealistic_coded
x <- s1_cleaned_data$Unrealistic_coded
x_label <- "Perceived Unrealistic Reason"
y <- s1_cleaned_data$author_trust_combined_score
y_label <- "Author Trust"

```

{{< include "_ANOVA.qmd" >}}

Survey Purpose / Condition Interaction

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Unrealistic, 
                    data = s1_cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Unrealistic,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", colors = safe_pal)

fit_i <- lm(author_trust_combined_score ~ Condition * Unrealistic_coded, 
                    data = s1_cleaned_data |> filter(Unrealistic == "Yes"))

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Unrealistic_coded,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="bar", , colors = safe_pal)
```

<!-- #### Correlations -->

<!-- ```{r} -->
<!-- correlation_data <- s1_cleaned_data |> select(author_trust_combined_score, -->
<!--                                            content_trust_combined_score, -->
<!--                                            likeability_score,  -->
<!--                                            competence_score,  -->
<!--                                            expertise_score,  -->
<!--                                            integrity_score,  -->
<!--                                            benevolence_score,  -->
<!--                                            anthropomorphism_score,  -->
<!--                                            content_trust_appelman_score, -->
<!--                                            content_trust_behaviour_score, -->
<!--                                            author_trust_METI_score, -->
<!--                                            author_trust_behaviour_score) -->

<!-- corr_matrix = cor(correlation_data) -->

<!-- corr_matrix_p <- corr.test(correlation_data) -->

<!-- kable(head(corr_matrix)) -->
<!-- corrplot(corr_matrix, type="upper", method = "circle", order = "hclust",  -->
<!--          addCoef.col = "white", # Add coefficient of correlation -->
<!--          tl.col="black", tl.srt=45, #Text label color and rotation -->
<!--          p.mat = corr_matrix_p$p, sig.level = 0.01, insig = "blank",  -->
<!--          diag = FALSE) -->

<!-- ``` -->

<!-- ##### Correlations at High Condition -->

<!-- ```{r} -->
<!-- correlation_data_high <- s1_cleaned_data |>  -->
<!--   filter(Condition == "High") |>  -->
<!--   select(author_trust_combined_score, content_trust_combined_score, likeability_score, competence_score, expertise_score, integrity_score, benevolence_score) -->


<!-- corr_matrix_high = cor(correlation_data_high) -->
<!-- corr_matrix_p_high <- corr.test(correlation_data_high) -->

<!-- kable(head(corr_matrix_high)) -->
<!-- corrplot(corr_matrix_high, type="upper", method = "circle", order = "hclust",  -->
<!--          addCoef.col = "white", # Add coefficient of correlation -->
<!--          tl.col="black", tl.srt=45, #Text label color and rotation -->
<!--          p.mat = corr_matrix_p_high$p, sig.level = 0.01, insig = "blank",  -->
<!--          diag = FALSE) -->
<!-- ``` -->

<!-- ##### Correlations at Medium Condition -->

<!-- ```{r} -->
<!-- correlation_data_medium <- s1_cleaned_data |>  -->
<!--   filter(Condition == "Medium") |>  -->
<!--   select(author_trust_combined_score, content_trust_combined_score, likeability_score, competence_score, expertise_score, integrity_score, benevolence_score) -->


<!-- corr_matrix_medium = cor(correlation_data_medium) -->
<!-- corr_matrix_p_medium <- corr.test(correlation_data_medium) -->

<!-- kable(head(corr_matrix_medium)) -->
<!-- corrplot(corr_matrix_medium, type="upper", method = "circle", order = "hclust",  -->
<!--          addCoef.col = "white", # Add coefficient of correlation -->
<!--          tl.col="black", tl.srt=45, #Text label color and rotation -->
<!--          p.mat = corr_matrix_p_medium$p, sig.level = 0.01, insig = "blank",  -->
<!--          diag = FALSE) -->
<!-- ``` -->

<!-- ##### Correlations at Low Condition -->

<!-- ```{r} -->
<!-- correlation_data_low <- s1_cleaned_data |>  -->
<!--   filter(Condition == "Low") |>  -->
<!--   select(author_trust_combined_score, content_trust_combined_score, likeability_score, competence_score, expertise_score, integrity_score, benevolence_score) -->


<!-- corr_matrix_low = cor(correlation_data_low) -->
<!-- corr_matrix_p_low <- corr.test(correlation_data_low) -->


<!-- kable(head(corr_matrix_low)) -->
<!-- corrplot(corr_matrix_low, type="upper", method = "circle", order = "hclust",  -->
<!--          addCoef.col = "white", # Add coefficient of correlation -->
<!--          tl.col="black", tl.srt=45, #Text label color and rotation -->
<!--          p.mat = corr_matrix_p_low$p, sig.level = 0.01, insig = "blank",  -->
<!--          diag = FALSE) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- library(cocor) -->

<!-- cocor(~ `content_trust_combined_score` + `expertise_score` | `content_trust_combined_score` + `expertise_score`,  -->
<!--       data = list( -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "High")),  -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "Low")) -->
<!--       ) -->
<!-- ) -->

<!-- ``` -->

<!-- ```{r} -->
<!-- cocor(~ `content_trust_combined_score` + `competence_score` | `content_trust_combined_score` + `competence_score`,  -->
<!--       data = list( -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "High")),  -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "Low")) -->
<!--       ) -->
<!-- ) -->

<!-- ``` -->

<!-- ```{r} -->
<!-- cocor(~ `content_trust_combined_score` + `likeability_score` | `content_trust_combined_score` + `likeability_score`,  -->
<!--       data = list( -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "High")),  -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "Low")) -->
<!--       ) -->
<!-- ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- cocor(~ `content_trust_combined_score` + `benevolence_score` | `content_trust_combined_score` + `benevolence_score`,  -->
<!--       data = list( -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "High")),  -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "Low")) -->
<!--       ) -->
<!-- ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- cocor(~ `content_trust_combined_score` + `integrity_score` | `content_trust_combined_score` + `integrity_score`,  -->
<!--       data = list( -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "High")),  -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "Low")) -->
<!--       ) -->
<!-- ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- cocor(~ `content_trust_combined_score` + `author_trust_combined_score` | `content_trust_combined_score` + `author_trust_combined_score`,  -->
<!--       data = list( -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "High")),  -->
<!--         as.data.frame(s1_cleaned_data |> filter(Condition == "Low")) -->
<!--       ) -->
<!-- ) -->
<!-- ``` -->

# References

```{r}
my_packages = c("rstatix", "stats", "effectsize", "psych", "interactions",
                 "corrplot", "performance", "FSA", "see")

write_bib(my_packages, file= "outputs/s1/packages.bib")
```
