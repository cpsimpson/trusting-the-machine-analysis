---
title: "Analysis"
author: "Caroline Simpson"
format: html
theme: cerulean
df_print: kable
code_folding: hide
toc: true
toc_float:
  collapsed: true
  smooth_scroll: false
toc_depth: 7
editor: visual
---

```{r}

library(knitr)
library(kableExtra)
library(rstatix)
library(tidyverse)
library(qualtRics)
library(haven)
library(jtools)
library(forcats)
library(FactoMineR)
library(psych)
library(interactions)
library(corrplot)

library(performance)
library(see)

source("./helpers.R")

```

# Trusting the machine: Epistemic trust and anthropomorphism in generative artificial intelligence

**Research Question**: What effect does anthropomorphism have on level of trust in generative AI and the content it creates?  

My **hypothesis** is that there will be an increase in epistemic trust with increasing levels of anthropomorphism. 

## Data Analysis

### Load data

```{r}
# raw_data <- read_spss(
#   #"data/Thesis+-+Trusting+the+Machine+-+Copy+For+Testing_December+4,+2024_21.34.sav"
#   # "data/Thesis+-+Trusting+the+Machine_December+4,+2024_19.13.sav"
#   # "data/Thesis+-+Trusting+the+Machine_November+30,+2024_13.06.sav"
#   "data/Thesis+-+Trusting+the+Machine_December+6,+2024_16.22.sav"
#   )

raw_data <- read_survey(
  "data/Thesis+-+Trusting+the+Machine_January+18,+2025_16.09_coded.csv", 
  col_types = readr::cols(Languages = readr::col_character())
)

```

```{r}

raw_data$Appelman_1 <- as.numeric(as.character(raw_data$Appelman_1))
raw_data$Appelman_2 <- as.numeric(as.character(raw_data$Appelman_2))
raw_data$Appelman_3 <- as.numeric(as.character(raw_data$Appelman_3))
raw_data$Appelman_4 <- as.numeric(as.character(raw_data$Appelman_4))
raw_data$Appelman_5 <- as.numeric(as.character(raw_data$Appelman_5))
raw_data$Appelman_6 <- as.numeric(as.character(raw_data$Appelman_6))

raw_data$TrustBehaviour_1 <- as.numeric(as.character(raw_data$TrustBehaviour_1))
raw_data$TrustBehaviour_2 <- as.numeric(as.character(raw_data$TrustBehaviour_2))
raw_data$TrustBehaviour_3 <- as.numeric(as.character(raw_data$TrustBehaviour_3))
raw_data$TrustBehaviour_4 <- as.numeric(as.character(raw_data$TrustBehaviour_4))
raw_data$TrustBehaviour_5 <- as.numeric(as.character(raw_data$TrustBehaviour_5))
raw_data$TrustBehaviour_6 <- as.numeric(as.character(raw_data$TrustBehaviour_6))
raw_data$TrustBehaviour_7 <- as.numeric(as.character(raw_data$TrustBehaviour_7))
raw_data$TrustBehaviour_8 <- as.numeric(as.character(raw_data$TrustBehaviour_8))
raw_data$TrustBehaviour_9 <- as.numeric(as.character(raw_data$TrustBehaviour_9))

# setup factor variables
raw_data$Condition <- factor(raw_data$Condition, levels = c("Low", "Medium", "High"))

raw_data$Sex <- cut(raw_data$Sex, 4, labels = c("Male", "Female", "Intersex", "Prefer not to say"))
raw_data$Gender <- cut(raw_data$Gender, 5, labels = c("Non-binary / third gender", "Man", "Woman", "Prefer to self-describe", "Prefer not to say"))
raw_data$Education <- cut(raw_data$Education, 9, labels = c(
  "SomePrimary", "Primary", "SomeSecondarySchool", "Secondary", "VocationalOrSimilar", "SomeUniversity", "UniversityBachelorsDegree", "GraduateProfessionalDegree", "PreferNotToSay"
))
raw_data$English <- cut(raw_data$English, 3, labels = c("Yes", "No", "Learned English concurrently with another language"))

raw_data$age_range <- cut(raw_data$Age_1, 6)
```

Number of participants in raw data = `r nrow(raw_data)`.

### Manual Processing

Review and code Survey purpose check (what they think this study is about, not the attention check)

-   Manually coded the response values with the following key:

    -   0 = no answer provided

    -   1 = identified the survey was about AI content, perception of AI, human versus AI distinction

    -   2 = nonsensical text

    -   3 = values that describe a purpose

    -   4 = random word

    -   5 = unsure

    -   6 = "the study was interesting" or "good" and variations of this

    -   7 = None

```{r}
raw_data |> 
  group_by(SurveyTopicCheck_coded) |> 
  summarise(n=n())
```

Review and code Unrealistic parts of survey.

-   Unrealistic

    -   1 = No

    -   2 = Yes

-   Unrealistic_coded -\> Manually coded the response values with the following key:

    -   0 = no answer provided

    -   1 = believe descriptions written by AI or content written by AI when told human or content written by human when told AI

    -   2 = don't believe that traits make sense to apply to AI

    -   3 = it all seemed realistic

    -   4 = description of AI was not believable

    -   5 = random text

    -   6 = unsure why they were asked questions about AI (in High condition)

```{r}

raw_data |> 
  group_by(Unrealistic, Unrealistic_coded) |> 
  summarise(n=n())
```

Check technical issues values.

```{r}

raw_data |> 
  group_by(TechnicalIssues) |> 
  summarise(n=n())
```

### Reverse Coding

Reverse code items for each scale where appropriate

```{r}

# 4, 5

recoded_data <- raw_data |> 
  mutate(
    TrustBehaviour_4r = 7 - TrustBehaviour_4,
    TrustBehaviour_5r = 7 - TrustBehaviour_5,
    GodspeedMETI_10r = 100 - GodspeedMETI_10,
    GodspeedMETI_13r = 100 - GodspeedMETI_13,
    GodspeedMETI_15r = 100 - GodspeedMETI_15,
    GodspeedMETI_16r = 100 - GodspeedMETI_16,
    GodspeedMETI_17r = 100 - GodspeedMETI_17,
    GodspeedMETI_18r = 100 - GodspeedMETI_18,
    GodspeedMETI_19r = 100 - GodspeedMETI_19,
    GodspeedMETI_20r = 100 - GodspeedMETI_20,
    GodspeedMETI_21r = 100 - GodspeedMETI_21,
    GodspeedMETI_22r = 100 - GodspeedMETI_22,
    GodspeedMETI_23r = 100 - GodspeedMETI_23,
    GodspeedMETI_24r = 100 - GodspeedMETI_24,
    GodspeedMETI_25r = 100 - GodspeedMETI_25,
    GodspeedMETI_26r = 100 - GodspeedMETI_26,
  )

```

### Clean Data

Filter out incomplete results

```{r}
cleaned_data <- recoded_data |>
  filter(EndDate >= "2024-12-04") |>  # Started on or after "2024-12-04" to remove test runs
  filter(Progress == 100) |>  # Completed surveys
  filter(ConsentForm == 1) |>  # Provided consent
  filter(Status == 0) |> # Used anonymous link to complete survey (not preview)
  filter(Reread != 1) |>  # Did not need to reread the instructions
  filter(TopicCheck == 1) |>  # Passed topic check (attention check)
  filter(
    (AgentTypeCheck == 1 & Condition == "Low") | 
      (AgentTypeCheck == 1 & Condition == "Medium") | 
      (AgentTypeCheck == 2 & Condition == "High") 
    ) |>  # Passed agent check (attention check)
  filter(GodspeedMETI_28 == 100) |>  # Explicit item value check (attention check)
  filter(GodspeedMETI_29 == 0) |> # Explicit item value check (attention check)
  filter(Q_RecaptchaScore == 1) |>  # Recaptcha score from Qualtrics == 1
  filter(Unrealistic_coded != 5 & SurveyTopicCheck_coded != 2)  # Free text field does not appear to be random keystrokes (Unrealistic experience in survey, study purpose)
```

Number of participants meeting basic criteria = `r nrow(cleaned_data)`.

#### Validate no duplicate participants

```{r}
duplicates <- cleaned_data |> 
  group_by(ResponseId) |> 
  summarise(n=n()) |>
  filter(n > 1) |>
  nrow()
  

```

There are `r if (duplicates == 0) "no duplicate participants" else paste (duplicates, "duplicates")`

***TODO***: Should we filter out the participants with technical issues?

```{r}

cleaned_data |> 
  group_by(TechnicalIssues) |> 
  summarise(n=n())

```

### Calculate Scale Scores

#### Define Score Components

```{r}

content_trust_score_appelman_cols = c("Appelman_1", "Appelman_2", "Appelman_3")

content_trust_score_behaviour_cols = c("TrustBehaviour_1", "TrustBehaviour_2",  "TrustBehaviour_3" ,"TrustBehaviour_4r", "TrustBehaviour_5r", "TrustBehaviour_6", "TrustBehaviour_9")

content_trust_score_combined_cols =  append(content_trust_score_appelman_cols, content_trust_score_behaviour_cols)

author_trust_score_behaviour_cols = c("TrustBehaviour_7", "TrustBehaviour_8")
author_trust_score_METI_cols = c("GodspeedMETI_10", "GodspeedMETI_13", "GodspeedMETI_15r", "GodspeedMETI_16r", "GodspeedMETI_17r", "GodspeedMETI_18r", "GodspeedMETI_19r", "GodspeedMETI_20r", "GodspeedMETI_21r", "GodspeedMETI_22r", "GodspeedMETI_23r", "GodspeedMETI_24r", "GodspeedMETI_25r", "GodspeedMETI_26r")

author_trust_score_combined_cols = append(author_trust_score_behaviour_cols, author_trust_score_METI_cols)

anthropomorphism_score_godspeed_cols = c("GodspeedMETI_1", "GodspeedMETI_2", "GodspeedMETI_3", "GodspeedMETI_4")
likeability_score_godspeed_cols = c("GodspeedMETI_5", "GodspeedMETI_6", "GodspeedMETI_7", "GodspeedMETI_8", "GodspeedMETI_9")
competence_score_godspeed_cols =  c("GodspeedMETI_10", "GodspeedMETI_11", "GodspeedMETI_12", "GodspeedMETI_13", "GodspeedMETI_14")

expertise_score_METI_cols = c("GodspeedMETI_10", "GodspeedMETI_13", "GodspeedMETI_15r", "GodspeedMETI_16r", "GodspeedMETI_17r", "GodspeedMETI_18r")
integrity_score_METI_cols = c("GodspeedMETI_19r", "GodspeedMETI_20r", "GodspeedMETI_21r", "GodspeedMETI_22r")
benevolence_score_METI_cols = c("GodspeedMETI_23r", "GodspeedMETI_24r", "GodspeedMETI_25r", "GodspeedMETI_26r")



```

-   Calculate scores for Content Trust, Author Trust, Anthropomorphism, Likeability, Competence, Expertise, Integrity, Benevolence

```{r}

cleaned_data <- cleaned_data |>
  mutate(
    content_trust_appelman_score = rowMeans(
      select(cleaned_data, all_of(content_trust_score_appelman_cols)), na.rm = TRUE),
    content_trust_behaviour_score = rowMeans(
      select(cleaned_data, all_of(content_trust_score_behaviour_cols)), na.rm = TRUE),
    content_trust_combined_score = rowMeans(
      select(cleaned_data, all_of(content_trust_score_combined_cols)), na.rm = TRUE),
    author_trust_behaviour_score = rowMeans(
      select(cleaned_data, all_of(author_trust_score_behaviour_cols)), na.rm = TRUE),
    author_trust_METI_score = rowSums(
      select(cleaned_data, all_of(author_trust_score_METI_cols)), na.rm = TRUE),
    author_trust_combined_score = rowMeans(
      select(cleaned_data, all_of(author_trust_score_combined_cols)), na.rm = TRUE),
    anthropomorphism_score = rowMeans(
      select(cleaned_data, all_of(anthropomorphism_score_godspeed_cols)), na.rm = TRUE),
    likeability_score = rowMeans(
      select(cleaned_data, all_of(likeability_score_godspeed_cols)), na.rm = TRUE),
    competence_score = rowMeans(
      select(cleaned_data, all_of(competence_score_godspeed_cols)), na.rm = TRUE), 
    expertise_score = rowSums(
      select(cleaned_data, all_of(expertise_score_METI_cols)), na.rm = TRUE), 
    integrity_score = rowSums(
      select(cleaned_data, all_of(integrity_score_METI_cols)), na.rm = TRUE), 
    benevolence_score = rowSums(
      select(cleaned_data, all_of(benevolence_score_METI_cols)), na.rm = TRUE)
  ) 

```

### Scale Inter-item Reliability Analysis

#### Anthropomorphism (Godspeed Subscale)

```{r}

cleaned_data |> 
  select(all_of(anthropomorphism_score_godspeed_cols)) |>
  psych::alpha()
```

#### Likeability (Godspeed Subscale)

```{r}

cleaned_data |> 
  select(all_of(likeability_score_godspeed_cols)) |>
  psych::alpha()

```

#### Competence (Godspeed Subscale)

```{r}

cleaned_data |> 
  select(all_of(competence_score_godspeed_cols)) |>
  psych::alpha()

```

#### Expertise (METI Subscale)

```{r}

cleaned_data |> 
  select(all_of(expertise_score_METI_cols)) |>
  psych::alpha()

```

#### Integrity (METI Subscale)

```{r}

cleaned_data |> 
  select(all_of(integrity_score_METI_cols)) |>
  psych::alpha()

```

#### Benevolence (Godspeed Subscale)

```{r}

cleaned_data |> 
  select(all_of(benevolence_score_METI_cols)) |>
  psych::alpha()

```

#### METI (Author Trust)

```{r}

cleaned_data |> 
  select(all_of(author_trust_score_METI_cols)) |>
  psych::alpha()

```

#### Trust Behaviour (Author Trust)

```{r}

cleaned_data |> 
  select(all_of(author_trust_score_behaviour_cols)) |>
  psych::alpha()

```

#### Combine Author Trust

```{r}

cleaned_data |> 
  select(all_of(author_trust_score_combined_cols)) |>
  psych::alpha()

```

#### Appelman (Content Trust)

```{r}

cleaned_data |> 
  select(all_of(content_trust_score_appelman_cols)) |>
  psych::alpha()

```

#### Trust Behaviour (Content Trust)

```{r}

cleaned_data |> 
  select(all_of(content_trust_score_behaviour_cols)) |>
  psych::alpha()

```

#### Combined Content Trust

```{r}

cleaned_data |> 
  select(all_of(content_trust_score_combined_cols)) |>
  psych::alpha()

```

-   ***TODO:*** Factor / Reliability analysis on Experience Data section items (or at least go through them and see what is there in more detail and which items likely should be grouped)

### 

### Sample Characteristics

```         
N=`r length(unique(cleaned_data$ResponseId))`
```

Participants per condition.

```{r}
cleaned_data |> 
  select(ResponseId, Condition) |>
  group_by(Condition) |>
  summarise(n = n())

```

-   Calculate demographics stats.

#### Age

```         
Age range: `r round(min(cleaned_data$Age_1, na.rm = TRUE), 2)` to `r round(max(cleaned_data$Age_1, na.rm = TRUE), 2)`
Mean age: `r round(mean(cleaned_data$Age_1, na.rm = TRUE), 2)`
Standard deviation: `r round(sd(cleaned_data$Age_1, na.rm = TRUE), 2)`
```

```{r}
cleaned_data |> 
  select(age_range) |>
  group_by(age_range) |>
  summarise(n = n())

cleaned_data |> 
  select(age_range, Condition) |>
  group_by(age_range, Condition) |>
  summarise(n = n())
```

#### Gender

```{r}

cleaned_data |> 
  select(Gender) |>
  group_by(Gender) |>
  summarise(n = n())

cleaned_data |> 
  select(Gender, Condition) |>
  group_by(Gender, Condition) |>
  summarise(n = n())

```

Limit analysis to Man / Woman comparison given small sample size for other values.

#### Sex

```{r}

cleaned_data |> 
  select(Sex) |>
  group_by(Sex) |>
  summarise(n = n())

cleaned_data |> 
  select(Sex, Condition) |>
  group_by(Sex, Condition) |>
  summarise(n = n())
```

Limit analysis to Male / Female comparison given small sample size for other values.

#### Education Level

```{r}

cleaned_data |> 
  select(Education) |>
  group_by(Education) |>
  summarise(n = n())

cleaned_data |> 
  select(Education, Condition) |>
  group_by(Education, Condition) |>
  summarise(n = n())

```

#### English as a First Language

```{r}

cleaned_data |> 
  select(English) |>
  group_by(English) |>
  summarise(n = n())

cleaned_data |> 
  select(English, Condition) |>
  group_by(English, Condition) |>
  summarise(n = n())

```

#### Other Languages

```{r}

cleaned_data |> 
  select(Languages) |>
  group_by(Languages) |>
  summarise(n = n())

cleaned_data |> 
  select(Languages, Condition) |>
  group_by(Languages, Condition) |>
  summarise(n = n())


```

### Manipulation Check

#### Anthropomorphism

We attempted to explicitly manipulated the level of anthropomorphism. Therefore, we would expect to see a significant difference in this score across the 3 conditions.

##### Plot

```{r}
violin_plot(cleaned_data, cleaned_data$Condition, cleaned_data$anthropomorphism_score, cleaned_data$Condition, "Anthropomorphism Scores")
```

##### Descriptive Statistics

###### Means

```{r}
cleaned_data |>
  select(Condition, anthropomorphism_score) |>
by(cleaned_data$Condition, summary)

```

###### Standard Deviation

```{r}
tapply(cleaned_data$anthropomorphism_score, cleaned_data$Condition, sd)
```

###### Variance

```{r}
tapply(cleaned_data$anthropomorphism_score, cleaned_data$Condition, var)
```

##### Inferential Statistics 

###### ANOVA

```{r}

aov_model <- aov(anthropomorphism_score ~ Condition, data = cleaned_data)

par(mfrow = c(2, 2))
plot(aov_model)

summary(aov_model)


```

###### T-tests

```{r}

t_high_medium = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(anthropomorphism_score),
  y = cleaned_data |> filter(Condition == "Medium") |> select(anthropomorphism_score)
)

t_high_medium

t_high_low = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(anthropomorphism_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(anthropomorphism_score)
)

t_high_low

t_medium_low = t.test(
  x = cleaned_data |> filter(Condition == "Medium") |> select(anthropomorphism_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(anthropomorphism_score)
)

t_medium_low

```

**The difference in anthropomorphism between Low and Medium conditions is not significant. Thus we must assume our manipulation was not effective between these conditions.**

Thoughts:

-   you can't just describe an AI as if it were human and get an anthropomorphic effect - why not?

-   avatar image was not effective in provoking effect.

-   overriding existing beliefs about AI / computers?

#### Likeability

We were not explicitly intending to manipulate likeability

##### Plot

```{r}
violin_plot(cleaned_data, cleaned_data$Condition, cleaned_data$likeability_score, cleaned_data$Condition, "Likeability Scores")
```

##### 

##### Descriptive Statistics

###### Means

```{r}
cleaned_data |>
  select(Condition, likeability_score) |>
by(cleaned_data$Condition, summary)

```

###### Standard Deviation

```{r}
tapply(cleaned_data$likeability_score, cleaned_data$Condition, sd)
```

###### Variance

```{r}
tapply(cleaned_data$likeability_score, cleaned_data$Condition, var)
```

##### Inferential Statistics 

###### ANOVA

```{r}

aov_model <- aov(likeability_score ~ Condition, data = cleaned_data)

par(mfrow = c(2, 2))
plot(aov_model)

summary(aov_model)

```

###### T-tests

```{r}

t_high_medium = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(likeability_score),
  y = cleaned_data |> filter(Condition == "Medium") |> select(likeability_score)
)

t_high_medium

t_high_low = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(likeability_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(likeability_score)
)

t_high_low

t_medium_low = t.test(
  x = cleaned_data |> filter(Condition == "Medium") |> select(likeability_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(likeability_score)
)

t_medium_low

```

There is a significant difference in likeability between the High condition and others.

#### Competence

We were not explicitly intending to manipulate competence

##### Plot

```{r}
violin_plot(cleaned_data, cleaned_data$Condition, cleaned_data$competence_score, cleaned_data$Condition, "Competence Scores")
```

##### 

##### Descriptive Statistics

###### Means

```{r}
cleaned_data |>
  select(Condition, competence_score) |>
by(cleaned_data$Condition, summary)

```

###### Standard Deviation

```{r}
tapply(cleaned_data$competence_score, cleaned_data$Condition, sd)
```

###### Variance

```{r}
tapply(cleaned_data$competence_score, cleaned_data$Condition, var)
```

##### Inferential Statistics 

###### ANOVA

```{r}

aov_model <- aov(competence_score ~ Condition, data = cleaned_data)

par(mfrow = c(2, 2))
plot(aov_model)

summary(aov_model)


```

###### T-tests

```{r}

t_high_medium = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(competence_score),
  y = cleaned_data |> filter(Condition == "Medium") |> select(competence_score)
)

t_high_medium

t_high_low = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(competence_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(competence_score)
)

t_high_low

t_medium_low = t.test(
  x = cleaned_data |> filter(Condition == "Medium") |> select(competence_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(competence_score)
)

t_medium_low

```

#### Expertise

We were not explicitly intending to manipulate expertise

##### Plot

```{r}
violin_plot(cleaned_data, cleaned_data$Condition, cleaned_data$expertise_score, cleaned_data$Condition, "Expertise Scores")
```

##### 

##### Descriptive Statistics

###### Means

```{r}
cleaned_data |>
  select(Condition, expertise_score) |>
by(cleaned_data$Condition, summary)

```

###### Standard Deviation

```{r}
tapply(cleaned_data$expertise_score, cleaned_data$Condition, sd)
```

###### Variance

```{r}
tapply(cleaned_data$expertise_score, cleaned_data$Condition, var)
```

##### Inferential Statistics 

###### ANOVA

```{r}

aov_model <- aov(expertise_score ~ Condition, data = cleaned_data)

par(mfrow = c(2, 2))
plot(aov_model)

summary(aov_model)


```

###### T-tests

```{r}

t_high_medium = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(expertise_score),
  y = cleaned_data |> filter(Condition == "Medium") |> select(expertise_score)
)

t_high_medium

t_high_low = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(expertise_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(expertise_score)
)

t_high_low

t_medium_low = t.test(
  x = cleaned_data |> filter(Condition == "Medium") |> select(expertise_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(expertise_score)
)

t_medium_low

```

#### Integrity

We were not explicitly intending to manipulate integrity

##### Plot

```{r}
violin_plot(cleaned_data, cleaned_data$Condition, cleaned_data$integrity_score, cleaned_data$Condition, "Integrity Scores")
```

##### 

##### Descriptive Statistics

###### Means

```{r}
cleaned_data |>
  select(Condition, integrity_score) |>
by(cleaned_data$Condition, summary)

```

###### Standard Deviation

```{r}
tapply(cleaned_data$integrity_score, cleaned_data$Condition, sd)
```

###### Variance

```{r}
tapply(cleaned_data$integrity_score, cleaned_data$Condition, var)
```

##### Inferential Statistics 

###### ANOVA

```{r}

aov_model <- aov(integrity_score ~ Condition, data = cleaned_data)

par(mfrow = c(2, 2))
plot(aov_model)

summary(aov_model)


```

###### T-tests

```{r}

t_high_medium = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(integrity_score),
  y = cleaned_data |> filter(Condition == "Medium") |> select(integrity_score)
)

t_high_medium

t_high_low = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(integrity_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(integrity_score)
)

t_high_low

t_medium_low = t.test(
  x = cleaned_data |> filter(Condition == "Medium") |> select(integrity_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(integrity_score)
)

t_medium_low

```

#### Benevolence

We were not explicitly intending to manipulate benevolence

##### Plot

```{r}
violin_plot(cleaned_data, cleaned_data$Condition, cleaned_data$benevolence_score, cleaned_data$Condition, "Benevolence Scores")
```

##### 

##### Descriptive Statistics

###### Means

```{r}
cleaned_data |>
  select(Condition, benevolence_score) |>
by(cleaned_data$Condition, summary)

```

###### Standard Deviation

```{r}
tapply(cleaned_data$benevolence_score, cleaned_data$Condition, sd)
```

###### Variance

```{r}
tapply(cleaned_data$benevolence_score, cleaned_data$Condition, var)
```

##### Inferential Statistics 

###### ANOVA

```{r}

aov_model <- aov(benevolence_score ~ Condition, data = cleaned_data)

par(mfrow = c(2, 2))
plot(aov_model)

summary(aov_model)

```

###### T-tests

```{r}

t_high_medium = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(benevolence_score),
  y = cleaned_data |> filter(Condition == "Medium") |> select(benevolence_score)
)

t_high_medium

t_high_low = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(benevolence_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(benevolence_score)
)

t_high_low

t_medium_low = t.test(
  x = cleaned_data |> filter(Condition == "Medium") |> select(benevolence_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(benevolence_score)
)

t_medium_low

```

### Main Analysis

#### Content Trust

##### Plot

```{r}
violin_plot(cleaned_data, cleaned_data$Condition, cleaned_data$content_trust_combined_score, cleaned_data$Condition, "Content Trust Scores")
```

##### 

##### Descriptive Statistics

```{r}
cleaned_data |>
  select(Condition, content_trust_combined_score) |>
by(cleaned_data$Condition, summary)

```

##### Inferential Statistics

Main Effect ANOVA

```{r}

aov_model <- aov(content_trust_combined_score ~ Condition, data = cleaned_data)

par(mfrow = c(2, 2))
plot(aov_model)

summary(aov_model)
```

No effect of anthropomorphism level on Content Trust

-   This implies there is a separation between the trust of the content and the trust in the source of the content.

```{r}


```

-   Look for effect in content trust by anthropomorphism condition. (ANOVA + t-tests) \<- main question

    -   Check for correlations with content trust

    -   Check for correlations with Likeability scores

    -   Check for correlations with Competence scores

    -   Check for correlations with Expertise scores

    -   Check for correlations with Integretiy scores

    -   Check for correlations with Benevolence scores

    -   Check for interactions with demographics. (Gender, sex, education, languages, age)

    -   Check for interactions with AI usage experience.

    -   Check for interactions with Science content experience.

    -   Check for interactions with Experience data.

    -   Check for interactions with survey purpose check.

    -   Check for interactions with unrealistic check.

#### Author Trust

##### Plot

```{r}
violin_plot(cleaned_data, cleaned_data$Condition, cleaned_data$author_trust_combined_score, cleaned_data$Condition, "Author Trust Scores")
```

##### 

##### Descriptive Statistics

```{r}
cleaned_data |>
  select(Condition, author_trust_combined_score) |>
by(cleaned_data$Condition, summary)

```

##### Inferential Statistics

```{r}

aov_model <- aov(author_trust_combined_score ~ Condition, data = cleaned_data)

par(mfrow = c(2, 2))
plot(aov_model)

summary(aov_model)
```

```{r}


t_high_medium = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(author_trust_combined_score),
  y = cleaned_data |> filter(Condition == "Medium") |> select(author_trust_combined_score)
)

t_high_medium

t_high_low = t.test(
  x = cleaned_data |> filter(Condition == "High") |> select(author_trust_combined_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(author_trust_combined_score)
)

t_high_low

t_medium_low = t.test(
  x = cleaned_data |> filter(Condition == "Medium") |> select(author_trust_combined_score),
  y = cleaned_data |> filter(Condition == "Low") |> select(author_trust_combined_score)
)

t_medium_low
```

Significant effect of anthropomorphism level between High - Medium and High - Low conditions, no effect between Low - Medium as expected given the lack of significance in manipulation.

##### Post-hoc Analysis

###### Correlations with Content Trust

```{r}
correlation_data <- cleaned_data |> select(author_trust_combined_score, content_trust_combined_score, likeability_score, competence_score, expertise_score, integrity_score, benevolence_score)

corr_matrix = cor(correlation_data)

corr_matrix_p <- corr.test(correlation_data)

kable(head(corr_matrix))
corrplot(corr_matrix, type="upper", method = "circle", order = "hclust", 
         addCoef.col = "white", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         p.mat = corr_matrix_p$p, sig.level = 0.01, insig = "blank", 
         diag = FALSE)

```

###### Correlations at High Condition

```{r}
correlation_data_high <- cleaned_data |> 
  filter(Condition == "High") |> 
  select(author_trust_combined_score, content_trust_combined_score, likeability_score, competence_score, expertise_score, integrity_score, benevolence_score)


corr_matrix = cor(correlation_data_high)
corr_matrix_p <- corr.test(correlation_data_high)

kable(head(corr_matrix))
corrplot(corr_matrix, type="upper", method = "circle", order = "hclust", 
         addCoef.col = "white", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         p.mat = corr_matrix_p$p, sig.level = 0.01, insig = "blank", 
         diag = FALSE)
```

###### Correlations at Medium Condition

```{r}
correlation_data_high <- cleaned_data |> 
  filter(Condition == "Medium") |> 
  select(author_trust_combined_score, content_trust_combined_score, likeability_score, competence_score, expertise_score, integrity_score, benevolence_score)


corr_matrix = cor(correlation_data_high)
corr_matrix_p <- corr.test(correlation_data_high)

kable(head(corr_matrix))
corrplot(corr_matrix, type="upper", method = "circle", order = "hclust", 
         addCoef.col = "white", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         p.mat = corr_matrix_p$p, sig.level = 0.01, insig = "blank", 
         diag = FALSE)
```

###### Correlations at Low Condition

```{r}
correlation_data_high <- cleaned_data |> 
  filter(Condition == "Low") |> 
  select(author_trust_combined_score, content_trust_combined_score, likeability_score, competence_score, expertise_score, integrity_score, benevolence_score)


corr_matrix = cor(correlation_data_high)
corr_matrix_p <- corr.test(correlation_data_high)

kable(head(corr_matrix))
corrplot(corr_matrix, type="upper", method = "circle", order = "hclust", 
         addCoef.col = "white", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         p.mat = corr_matrix_p$p, sig.level = 0.01, insig = "blank", 
         diag = FALSE)
```

###### Age

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * age_range, data = cleaned_data)

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = age_range,  geom = "bar")
```

Significant interaction between for age range 50 - 59.7 and 59.7 - 69.3

-   Thoughts: What if we did a PCA here instead of using set ranges?

###### Gender (Man / Woman only)

```{r}


fit_i <- lm(author_trust_combined_score ~ Condition * Gender, 
                    data = cleaned_data |> filter(Gender == "Man" | Gender == "Woman"))

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Gender,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="line")

```

###### Sex (Male / Female only)

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Sex, 
                    data = cleaned_data |> filter(Sex == "Male" | Sex == "Female"))

summ(fit_i)

cat_plot(fit_i, pred = Condition, modx = Sex,  plot.points = TRUE, jitter = 0.5, point.alpha = 0.25, geom="line")
```

###### Education

```{r}

fit_i <- lm(author_trust_combined_score ~ Condition * Education, 
                    data = cleaned_data)

summ(fit_i)

```

AI Usage Experience

```{r}

```

Science Content Experience

```{r}

```

Experience

```{r}

```

Survey Purpose Check

```{r}

```

Unrealistic Check

```{r}

```

# Appendix A

```{r child='variables.rmd'}
```
